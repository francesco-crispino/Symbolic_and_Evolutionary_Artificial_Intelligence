{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8cdc5a",
   "metadata": {},
   "source": [
    "# CNN Inference with NumPy\n",
    "In the classic CNN behaviour, we are given an image, the kernel passes over each subset of the image and for each subset it computes the sum of element-wise products. If done with vanilla Python, this procedure results in a slow execution. In PyTorch the problem is solved thanks to the framework given by the module itself. The idea of using numpy consists in transforming the given image in a matrix where each row is composed by one of the subset of the image interested in the convolution with the kernel, then vectorize the kernel and then perform the convolution step by simply operating a dot product between the subset and the kernel. This operation is fast in numpy, which is the Python module responsible for numeric computations. This approach is good but it introduces redundancy in data. A tradeoff between memory and cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842de893",
   "metadata": {},
   "source": [
    "# provare jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8cf62",
   "metadata": {},
   "source": [
    "`PLACEHOLDER`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b36d8b",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce4150",
   "metadata": {},
   "source": [
    "### Kernel Multiplication\n",
    "Convolving an image of dimensions 800 x 600 x 3 where 3 is the number of channels (one for red, one for green and one for blue) with a kernel of size 2x2x3 outputs an image of dimensions 799x599x1. Kernel's number of channels must match the number of channels of the input image. Therefore if i want, for example, to obtain a color image as the result of a convolution, i would need to convolve the input image with three kernels of three channels. Another way to see this is that the number of kernels i use in the convolution will become the number of channels for the output image \n",
    "\n",
    "`X = X[::3,:]` means \"Please select the first three rows of matrix X and return them\"\n",
    "\n",
    "### Channels Problem: How to consider multiple channels:\n",
    "taking the previous matrix as an example, and adding a channel where every number is the corresponding of the first channel but *100 we obtain:\n",
    "01,02,05,06,101,102,105,106\n",
    "Which means just append the next channel's corresponding flattened window to the previous one\n",
    "\n",
    "### Batch Problem: How to consider multiple images:\n",
    "just add the obtained windows at the end of the ones of the previous image, so instead of having a 5 rows 9 columns matrix of windows the result will be a matrix of 10 rows and 9 columns.\n",
    "\n",
    "### Final input management\n",
    "The more images can be stacked in the input, the faster the training will be, therefore the stack dimension must be taken into account. If the desire is to manage stacks of 8, 800x600 resolution color images (numbers were chosen so that they are better recognizable) with a 5x4 kernel, the function to create windows will have this shape:\n",
    "\n",
    "`X = np.random.rand(8*3*800*600).reshape(8,3,800,600)`\n",
    "\n",
    "`y = np.lib.stride_tricks.sliding_window_view(X,(1,3,5,4)).reshape(-1,(3*5*4))`\n",
    "\n",
    "Which translates in:\n",
    "\n",
    "`y = np.lib.stride_tricks.sliding_window_view(X,(1,CHANNEL_SIZE,KERNEL_WIDTH,KERNEL_HEIGHT))`\n",
    "\n",
    "`y = y.reshape(-1,(CHANNEL_SIZE*KERNEL_WIDTH*KERNEL_HEIGHT))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42f52d",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1739ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trials = True\n",
    "def tprint(value):\n",
    "    print(value) if trials else print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76440db3",
   "metadata": {},
   "source": [
    "### Inefficient Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPooling2DIneff(batch_of_images,win_size = 2, stride=2):\n",
    "    # very inefficient... but it works...\n",
    "    # it gives the same result as PyTorch's nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "    #print(batch_of_images.shape)\n",
    "    niw = round(iw/2) if iw % 2 == 0 else round(iw/2)-1\n",
    "    nih = round(ih/2) if ih % 2 == 0 else round(ih/2)-1\n",
    "    batch = []\n",
    "    for bb in range(bs):\n",
    "        channel=[]\n",
    "        for cc in range(nc):\n",
    "            y=[]\n",
    "            for i in range(0,ih,stride):\n",
    "                for j in range(0,iw,stride):\n",
    "                    if (j+win_size)>iw:\n",
    "                        continue\n",
    "                    if (i+win_size)>ih:\n",
    "                        continue\n",
    "                    y.append(batch_of_images[bb,cc,i:(i+win_size),j:(j+win_size)].max())\n",
    "            y=np.array(y).reshape(niw,nih)\n",
    "            channel.append(y)\n",
    "        batch.append(channel)\n",
    "    return np.array(batch)\n",
    "## this is an example\n",
    "#X = np.arange(1,(6*6*2*2)+1).reshape(2,2,6,6)\n",
    "#print(X)\n",
    "#r=MaxPooling2D(X)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee45ce",
   "metadata": {},
   "source": [
    "### Sliding Window View\n",
    "To implement the im2col convolution approach, the first thing to do is creating the matrix of windows from the given image. This can be done with the helpful function `np.lib.stride_tricks.sliding_window_view(image,kernel_shape)` which exactly returns what this approach needs. In the next panel the functioning of this function will be done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7d5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2  3]\n",
      "   [ 4  5  6]\n",
      "   [ 7  8  9]]\n",
      "\n",
      "  [[10 11 12]\n",
      "   [13 14 15]\n",
      "   [16 17 18]]]\n",
      "\n",
      "\n",
      " [[[19 20 21]\n",
      "   [22 23 24]\n",
      "   [25 26 27]]\n",
      "\n",
      "  [[28 29 30]\n",
      "   [31 32 33]\n",
      "   [34 35 36]]]]\n",
      "desired result\n",
      "[1,2,4,5]\n",
      "[2,3,5,6]\n",
      "...\n",
      "correct one:\n",
      "wrong: after the first window there is the first window of the channel\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,(2*2*3*3)+1).reshape(2,2,3,3)\n",
    "tprint(X)\n",
    "tprint(\"desired result\")\n",
    "tprint(\"[1,2,4,5]\")\n",
    "tprint(\"[2,3,5,6]\")\n",
    "tprint(\"...\")\n",
    "tprint(\"correct one:\")\n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,1,2,2))\n",
    "tprint(\"wrong: after the first window there is the first window of the channel\")\n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,1,2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965932c",
   "metadata": {},
   "source": [
    "### Back from Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13611bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 0. 4. 0.]\n",
      " [0. 0. 0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "X= np.zeros(4*4).reshape(4,4)\n",
    "values = np.array([1,2,3,4]).reshape(2,2)\n",
    "indices=np.array([0,1,3,2]).reshape(2,2)\n",
    "print(X)\n",
    "np.add.at(X,(indices,indices),values)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b832470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "row,col\n",
      "[1 0 1 0] [1 0 0 1]\n",
      "r_out_idx\n",
      "[[0 0]\n",
      " [1 1]]\n",
      "c_out_idx\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "vert_start\n",
      "[[0 0]\n",
      " [2 2]]\n",
      "horiz_start\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "idx_row_in_window_reshaped\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "idx_col_in_window_reshaped\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "abs_row_coords\n",
      "[[1 0]\n",
      " [3 2]]\n",
      "abs_col_coords\n",
      "[[1 2]\n",
      " [0 3]]\n",
      "back_X\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "back_X\n",
      "[[0. 0. 3. 0.]\n",
      " [0. 7. 0. 0.]\n",
      " [0. 0. 0. 5.]\n",
      " [4. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.arange(1,17).reshape(4,4)\n",
    "print(X)\n",
    "stride = winSize = 2\n",
    "small_X = np.array([6,5,6,7]).reshape(2,2)\n",
    "small_dX = np.array([7,3,4,5]).reshape(2,2)\n",
    "H_out,W_out = small_dX.shape\n",
    "ind = np.array([3,0,2,1])\n",
    "back_X = np.zeros(X.shape)\n",
    "row = ind // winSize # if [3,3,3,3] // 2 returns [1,1,1,1]\n",
    "col = ind % winSize # if [3,3,3,3] // 2 returns [1,1,1,1]\n",
    "print(\"row,col\")\n",
    "print(row,col)\n",
    "# it means, the first element must be at row one and col one starting from zero.\n",
    "r_out_idx, c_out_idx = np.indices((H_out, W_out))\n",
    "print(\"r_out_idx\")\n",
    "print(r_out_idx)\n",
    "print(\"c_out_idx\")\n",
    "print(c_out_idx)\n",
    "\n",
    "vert_start = r_out_idx * stride # Forma (bs, nc, H_out, W_out)\n",
    "horiz_start = c_out_idx * stride # Forma (bs, nc, H_out, W_out)\n",
    "print(\"vert_start\")\n",
    "print(vert_start)\n",
    "print(\"horiz_start\")\n",
    "print(horiz_start)\n",
    "#    c. Calcola le coordinate assolute finali in dA_prev\n",
    "#       idx_row_in_window e idx_col_in_window devono essere \"broadcastabili\" o\n",
    "#       avere la stessa forma di vert_start e horiz_start se non sono già piatte.\n",
    "#       Poiché indices_flat era (bs*nc*H_out*W_out,), rimodelliamoli:\n",
    "idx_row_in_window_reshaped = row.reshape(H_out, W_out)\n",
    "idx_col_in_window_reshaped = col.reshape(H_out, W_out)\n",
    "print(\"idx_row_in_window_reshaped\")\n",
    "print(idx_row_in_window_reshaped)\n",
    "print(\"idx_col_in_window_reshaped\")\n",
    "print(idx_col_in_window_reshaped)\n",
    "abs_row_coords = vert_start + idx_row_in_window_reshaped # Forma (bs, nc, H_out, W_out)\n",
    "abs_col_coords = horiz_start + idx_col_in_window_reshaped # Forma (bs, nc, H_out, W_out)\n",
    "print(\"abs_row_coords\")\n",
    "print(abs_row_coords)\n",
    "print(\"abs_col_coords\")\n",
    "print(abs_col_coords)\n",
    "# 4. Usa np.add.at per sommare i gradienti d_out nelle posizioni calcolate di dA_prev.\n",
    "#    np.add.at(array, indici, valori_da_aggiungere)\n",
    "#    Gli 'indici' devono essere una tupla di array di indici per ogni dimensione.\n",
    "#    Tutti gli array in 'indici' e 'valori_da_aggiungere' devono essere broadcastabili\n",
    "#    a una forma comune, o essere appiattiti in modo consistente.\n",
    "\n",
    "#    Creiamo gli indici per np.add.at:\n",
    "#    Tutti questi array (b_idx, ch_idx, abs_row_coords, abs_col_coords, d_out)\n",
    "#    hanno già la stessa forma (bs, nc, H_out, W_out), quindi NumPy\n",
    "#    li gestirà elemento per elemento quando usati come indici e valori.\n",
    "\n",
    "indices_for_add_at = (\n",
    "    abs_row_coords,         # Indici per la dimensione altezza di dA_prev\n",
    "    abs_col_coords          # Indici per la dimensione larghezza di dA_prev\n",
    ")\n",
    "print(\"back_X\")\n",
    "print(back_X)\n",
    "np.add.at(back_X, indices_for_add_at, small_dX)\n",
    "print(\"back_X\")\n",
    "print(back_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93155ee2",
   "metadata": {},
   "source": [
    "### Striding\n",
    "The next panel is devoted to explore the striding, achieved using the preceding, function along with the `[:,:,::2,::2]` construct that, respectively, leaves untouched the number of images in the batch and the number of channels, but selects one row every two and one column every two. rows and columns after the sliding window, uniquely identify one window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedbc941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]\n",
      "   [ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]\n",
      "   [25 26 27 28]\n",
      "   [29 30 31 32]]]]\n",
      "[[ 1  2  5  6]\n",
      " [17 18 21 22]\n",
      " [ 3  4  7  8]\n",
      " [19 20 23 24]\n",
      " [ 9 10 13 14]\n",
      " [25 26 29 30]\n",
      " [11 12 15 16]\n",
      " [27 28 31 32]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,16*2+1).reshape(1,2,4,4)\n",
    "tprint(X)\n",
    "# basically [::2,::2] selects every two rows and every two columns, where in this case elements are 3 dimensional matrices of 2 by 2 so the \n",
    "# selection eliminates the desired elements, resulting in a stride 2 convolution \n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,2,2,2))[:,:,::2,::2]\n",
    "#y = np.lib.stride_tricks.as_strided(X,shape=(2,2),strides=[1,2,3,4])\n",
    "tprint(y.reshape(-1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087d69f",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b40418",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e55bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7da90c",
   "metadata": {},
   "source": [
    "### Loading images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8634158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Leggi intestazione: magic number, numero immagini, righe, colonne\n",
    "        magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        # Leggi tutti i pixel e convertili in array numpy\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        # Ridimensiona l'array in (num_images, rows, cols)\n",
    "        images = images.reshape((num_images, rows, cols))\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "images = load_mnist_images('MNIST/train-images-idx3-ubyte')\n",
    "labels = load_mnist_labels('MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "print(images.shape)  # (60000, 28, 28)\n",
    "print(labels.shape)  # (60000,)\n",
    "one_hot_labels = np.zeros(labels.shape[0]*10).reshape((labels.shape[0]),10)\n",
    "for i in range(len(labels)):\n",
    "    one_hot_labels[i][labels[i]]=1\n",
    "labels = one_hot_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89060d9",
   "metadata": {},
   "source": [
    "## CNN Structure\n",
    "The goal is achieving over 90% of accuracy with a simple structure, therefore this would be the set of layers:\n",
    "- Convolutional Layer with 32 2x2 filters and ReLU activation: i: (B x C X 28 x 28), o: (B x 32 x 26 x 26)\n",
    "- Max Pooling layer with 2x2 filter: i: (B x 32 x 26 x 26), o: (B x 32 x 13 x 13)\n",
    "- Convolutional Layer with 32 2x2 filters and ReLU activation: i: (B x 13 x 13 x 32), o: (B x 11 x 11 x 64)\n",
    "- Linear Fully Connected Layer with ReLU activation: i: (B x 7744), o: (B x 250)\n",
    "- Linear Fully Connected Layer with Softmax activation: i: (B x 250), o: (B x 10)\n",
    "- Cross-Entropy Loss: -sum(true_probability_distribution*log(predicted_probability_distribution))\n",
    "\n",
    "where B is the batch_size and C is the number of channels, that for MNIST digits is just one, since they are greyscale images.\n",
    "\n",
    "The idea is to reduce everything to a matrix-matrix multiplication which is super fast in NumPy, an optimized mathematical module for Python, by taking an image and create a matrix containing for each row the flattened window that would enter the convolution, as an example:\n",
    "the first 2 flattened windows of this matrix:\n",
    "01,02,03,04\n",
    "05,06,07,08\n",
    "09,10,11,12\n",
    "13,14,15,16\n",
    "for a kernel 2x2 of stride 1 are:\n",
    "01,02,05,06\n",
    "02,03,06,07\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af530dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [4 2]]\n",
      "[[0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([-4,0,4,2]).reshape(2,2)\n",
    "reluX = np.maximum(0,X)\n",
    "print(reluX)\n",
    "BReluX=reluX\n",
    "BReluX[BReluX>0]=1\n",
    "print(BReluX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8946b2c",
   "metadata": {},
   "source": [
    "### Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9662d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "k\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "X_c\n",
      "[[14. 18. 22.]\n",
      " [30. 34. 38.]\n",
      " [46. 50. 54.]]\n",
      "This is the backward of the ReLU Convolution\n",
      "dX,X,kernel shapes\n",
      "(4, 4)\n",
      "(9, 4)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "def ReLU_Convolution(batch_of_images,kernel,p=0,s=1):\n",
    "    if len(kernel.shape)==2:\n",
    "        kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        nc = 1\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "    else:\n",
    "        ac, kc, kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        #p = 0 # padding\n",
    "        #s = 1 # stride\n",
    "        # im2col: Window creation\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "    # Convolution\n",
    "    kernel = kernel.reshape((kw*kh*nc),-1)\n",
    "    c_m = window_m @ kernel # convolved image matrix\n",
    "    # ReLU activation\n",
    "    r_c_m = np.maximum(0,c_m) # convolved image matrix after ReLU activation\n",
    "    \n",
    "    niw = round(((iw-kw+(2*p))/s)+1) # new image width\n",
    "    nih = round(((ih-kh+(2*p))/s)+1) # new image height\n",
    "    \n",
    "    # First operate a reshape keeping spatial ordering, which has channels at the end\n",
    "    if len(kernel.shape)==2:\n",
    "        reshaped_correct_order = r_c_m.reshape(nih, niw)\n",
    "    else:\n",
    "        output_temp = r_c_m.reshape(bs, nih, niw, kc)\n",
    "        # Transpose to have input in shapes (batch, canali_output, height, width)\n",
    "        reshaped_correct_order = output_temp.transpose(0, 3, 1, 2)\n",
    "    return reshaped_correct_order\n",
    "\n",
    "\n",
    "def ReLU_Convolution_Backward(batch_of_images,kernel,dX,p=0,s=1):\n",
    "    print(\"This is the backward of the ReLU Convolution\")\n",
    "    if len(kernel.shape)==2:\n",
    "        kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        nc = 1\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "        window_m_dx = np.lib.stride_tricks.sliding_window_view(dX,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix of dX\n",
    "    else:\n",
    "        ac, kc, kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        #p = 0 # padding\n",
    "        #s = 1 # stride\n",
    "        # im2col: Window creation\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "        window_m_dx = np.lib.stride_tricks.sliding_window_view(dX,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix of dX\n",
    "    # Convolution\n",
    "    kernel = kernel.reshape((kw*kh*nc),-1)\n",
    "    c_m = window_m @ kernel # convolved image matrix\n",
    "    # ReLU activation\n",
    "    r_c_m = np.maximum(0,c_m) # convolved image matrix after ReLU activation\n",
    "    r_c_m[r_c_m>0]=1 # Backward ReLU\n",
    "    print(\"dX,X,kernel shapes\")\n",
    "    print(window_m_dx.shape)\n",
    "    print(window_m.shape)\n",
    "    print(kernel.shape)\n",
    "\n",
    "\n",
    "X=np.arange(1,4*4+1).reshape(4,4)\n",
    "k = np.ones(1*2*2).reshape(2,2)\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"k\")\n",
    "print(k)\n",
    "X_c = ReLU_Convolution(X,k)\n",
    "print(\"X_c\")\n",
    "print(X_c)\n",
    "ReLU_Convolution_Backward(X,k,X_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76201de3",
   "metadata": {},
   "source": [
    "### Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPooling(boi, winSize=2, stride=2):\n",
    "    bs, nc, H_in, W_in = boi.shape\n",
    "\n",
    "    H_out = math.floor((H_in - winSize) / stride) + 1\n",
    "    W_out = math.floor((W_in - winSize) / stride) + 1\n",
    "\n",
    "    output_window_shape = (bs, nc, H_out, W_out, winSize, winSize)\n",
    "    \n",
    "    y_windows = np.lib.stride_tricks.as_strided(boi, shape=output_window_shape)\n",
    "\n",
    "    reshaped_y_for_max = y_windows.reshape(bs * nc * H_out * W_out, winSize * winSize)\n",
    "    \n",
    "    indices = np.argmax(reshaped_y_for_max, axis=1) # Indici piatti (0 a winSize*winSize-1)\n",
    "    max_values = reshaped_y_for_max.max(axis=1)\n",
    "    \n",
    "    pooled_output = max_values.reshape(bs, nc, H_out, W_out)\n",
    "    \n",
    "    cache = (boi.shape, indices, winSize, stride) # indices è 1D\n",
    "    return pooled_output, cache\n",
    "\n",
    "def BackwardMaxPooling(d_out, cache):\n",
    "\n",
    "    A_prev_shape, indices_flat, winSize, stride = cache\n",
    "    bs, nc, H_prev, W_prev = A_prev_shape\n",
    "    _, _, H_out, W_out = d_out.shape\n",
    "\n",
    "    dA_prev = np.zeros(A_prev_shape)\n",
    "\n",
    "    idx_row_in_window = indices_flat // winSize\n",
    "    idx_col_in_window = indices_flat % winSize  \n",
    "\n",
    "\n",
    "    b_idx, ch_idx, r_out_idx, c_out_idx = np.indices((bs, nc, H_out, W_out))\n",
    "\n",
    "    vert_start = r_out_idx * stride \n",
    "    horiz_start = c_out_idx * stride \n",
    "\n",
    "    idx_row_in_window_reshaped = idx_row_in_window.reshape(bs, nc, H_out, W_out)\n",
    "    idx_col_in_window_reshaped = idx_col_in_window.reshape(bs, nc, H_out, W_out)\n",
    "    \n",
    "    abs_row_coords = vert_start + idx_row_in_window_reshaped \n",
    "    abs_col_coords = horiz_start + idx_col_in_window_reshaped \n",
    "    \n",
    "    indices_for_add_at = (\n",
    "        b_idx,                  \n",
    "        ch_idx,                 \n",
    "        abs_row_coords,         \n",
    "        abs_col_coords        \n",
    "    )\n",
    "    \n",
    "    np.add.at(dA_prev, indices_for_add_at, d_out)\n",
    "    \n",
    "    return dA_prev\n",
    "\n",
    "#X = np.arange(1,33).reshape(2,1,4,4)\n",
    "#X[0,0,0,0]=100\n",
    "#\n",
    "#pooled,cache = MaxPooling2D(X)\n",
    "#print(cache)\n",
    "#dX = np.array([1,5,2,9,4,3,2,8]).reshape(2,1,2,2)\n",
    "#new_X = backward_maxpool_vectorized(dX,cache)\n",
    "#print(new_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58b263",
   "metadata": {},
   "source": [
    "### MLP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,axis=-1,keepdims=True))  # for numerical stability\n",
    "    return e_x / np.sum(e_x,axis=-1,keepdims=True)\n",
    "\n",
    "def ReLU_SoftMax_FullyConnected(input_array,w1,b1,w2,b2):\n",
    "    fl = (input_array @ w1)+b1 # first layer\n",
    "    fa = np.maximum(0,fl) # first activation: ReLU\n",
    "    sl = (fa @ w2)+b2 # second layer\n",
    "    sa = softmax(sl) # second activation: SoftMax\n",
    "    return fl,fa,sl,sa\n",
    "\n",
    "#print(softmax([1,2,3,100000]))\n",
    "#print(softmax_no_NS([1,2,3,1000]))\n",
    "#r = np.array(np.array([1,2,777,2]))\n",
    "#print(softmax(r))\n",
    "#r = np.array((np.array([1,2,777,2]),np.array([1,2,777,2]),np.array([1,2,777,2])))\n",
    "#print(softmax(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92146a63",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "For this classification problem, the best loss function is the cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(p,t):\n",
    "    # p stands for prediction and t stands for true label\n",
    "    # p = [0,0,1] and t = [1,0,0]\n",
    "    p = p+(1/100000) # for numerical stability\n",
    "    return -np.dot(t,np.log(p).T)\n",
    "\n",
    "#c = [1,1000000000000000,1,1]\n",
    "#c = softmax(c)\n",
    "#print(c)\n",
    "#c = crossEntropy(c,[0,1,0,0])\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe07056",
   "metadata": {},
   "source": [
    "## Training\n",
    "To train the model, computing the gradients is necessary. let's start from the cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9223383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.24it/s, average_loss=[[2.27330587]], state=0.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "bs=1 # batch size\n",
    "#ac is the adaptive channel, the number that corresponds to the amount of channels that the image has\n",
    "ac, kw, kh, kc = [1,3,3,32]\n",
    "k1 = np.random.rand(ac*kw*kh*kc).reshape(ac,kw,kh,kc)\n",
    "kc2 = 64\n",
    "ac2 = 32\n",
    "k2 = np.random.rand(ac2*kw*kh*kc2).reshape(ac2,kw,kh,kc2)\n",
    "h1 = 250\n",
    "w1 = np.random.rand(1600*250).reshape(1600,250)\n",
    "b1 = np.random.rand(250).reshape(1,250)\n",
    "w2 = np.random.rand(250*10).reshape(250,10)\n",
    "b2 = np.random.rand(10).reshape(1,10)\n",
    "length = 1 #labels.shape[0]\n",
    "lr = 0.01\n",
    "num_epochs = 1\n",
    "loop= tqdm(range(0,num_epochs,bs))\n",
    "for epoch in loop:\n",
    "    avg_loss = []\n",
    "    start_time = time.time()\n",
    "    for i in range(0,length,bs):\n",
    "        rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "        loop.set_postfix(average_loss=sum(avg_loss)/(len(avg_loss)+1),state=f\"{round(100*i/length,2)}%\")\n",
    "        im_sh1,mpInd1,mp1 = MaxPooling(rs1)\n",
    "        rs2 = ReLU_Convolution(mp1,k2)\n",
    "        im_sh2,mpInd2,mp2 = MaxPooling(rs2)\n",
    "        i_mlp = mp2.flatten()\n",
    "        fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2)\n",
    "\n",
    "        # Loss\n",
    "        loss = crossEntropy(pred,labels[i:(i+bs)])\n",
    "        avg_loss.append(loss)\n",
    "\n",
    "        # Backward\n",
    "        dL_dz2 = pred-labels[i:(i+bs)]\n",
    "        dL_dw2 = fa.T @ dL_dz2\n",
    "        dL_db2 = np.sum(dL_dz2, axis=0)\n",
    "        dL_dfa = dL_dz2 @ w2.T\n",
    "        dReLU = (fl > 0).astype(float)\n",
    "        dL_dfl = dL_dfa * dReLU\n",
    "        print(i_mlp.shape)\n",
    "        dL_dw1 = i_mlp.reshape(bs, -1).T @ dL_dfl\n",
    "        dL_db1 = np.sum(dL_dfl, axis=0)\n",
    "        dL_i_mlp = dL_dfl @ w1.T\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        w1 -= lr*dL_dw1\n",
    "        b1 -= lr*dL_db1\n",
    "        w2 -= lr*dL_dw2\n",
    "        b2 -= lr*dL_db2\n",
    "    loop.set_postfix(average_loss=sum(avg_loss)/len(avg_loss),state=f\"{round(100*i/length,2)}%\")\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c9eda",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f18df",
   "metadata": {},
   "source": [
    "### Inefficient Max Pooling Layer VS Efficient Max Pooling layer for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbd63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop with inefficient MaxPooling took: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop with efficient MaxPooling took: 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "################## PARAMETERS ###########################\n",
    "#\n",
    "#bs=1 # batch size\n",
    "##ac is the adaptive channel, the number that corresponds to the amount of channels that the image has\n",
    "#ac, kw, kh, kc = [1,3,3,32]\n",
    "#k1 = np.random.rand(ac*kw*kh*kc).reshape(ac,kw,kh,kc)\n",
    "#kc2 = 64\n",
    "#ac2 = 32\n",
    "#k2 = np.random.rand(ac2*kw*kh*kc2).reshape(ac2,kw,kh,kc2)\n",
    "#h1 = 250\n",
    "#w1 = np.random.rand(1600*250).reshape(1600,250)\n",
    "#b1 = np.random.rand(250).reshape(1,250)\n",
    "#w2 = np.random.rand(250*10).reshape(250,10)\n",
    "#b2 = np.random.rand(10).reshape(1,10)\n",
    "#\n",
    "################## INFERENCE #############################\n",
    "#length = 1000 # images.shape[0]\n",
    "#start_time = time.time()\n",
    "#for i in tqdm(range(0,length,bs)):\n",
    "#    continue\n",
    "#    rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "#    # For convolution only, these are the times for processing all the images\n",
    "#    # 11.0 seconds with bs = 10000\n",
    "#    # 10.0 seconds with bs = 1000\n",
    "#    # 09.9 seconds with bs = 100\n",
    "#    # 08.0 seconds with bs = 10\n",
    "#    # 06.0 seconds with bs = 1\n",
    "#    # Why ? the window creation scales as O(N*W) where W is the window size and N is the dimensions of the image.\n",
    "#    # Since images are stacked, they end up resulting as a single very big image which may cause problems.\n",
    "#    mp1 = MaxPooling2D(rs1)\n",
    "#    rs2 = ReLU_Convolution(mp1,k2)\n",
    "#    mp2 = MaxPooling2D(rs2)\n",
    "#    i_mlp = mp2.flatten()\n",
    "#    fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2) #softmax doesn't work properly if batch_size > 1\n",
    "#end_time = time.time()\n",
    "#print(f\"Loop with inefficient MaxPooling took: {round(end_time-start_time,2)}\")\n",
    "#start_time = time.time()\n",
    "#for i in tqdm(range(0,length,bs)):\n",
    "#    continue\n",
    "#    rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "#    # For convolution only, these are the times for processing all the images\n",
    "#    # 11.0 seconds with bs = 10000\n",
    "#    # 10.0 seconds with bs = 1000\n",
    "#    # 09.9 seconds with bs = 100\n",
    "#    # 08.0 seconds with bs = 10\n",
    "#    # 06.0 seconds with bs = 1\n",
    "#    # Why ? the window creation scales as O(N*W) where W is the window size and N is the dimensions of the image.\n",
    "#    # Since images are stacked, they end up resulting as a single very big image which may cause problems.\n",
    "#    mp1 = MaxPooling2D_Ef(rs1)\n",
    "#    rs2 = ReLU_Convolution(mp1,k2)\n",
    "#    mp2 = MaxPooling2D_Ef(rs2)\n",
    "#    i_mlp = mp2.flatten()\n",
    "#    fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2)\n",
    "#    #loss = crossEntropy\n",
    "#end_time = time.time()\n",
    "#print(f\"Loop with efficient MaxPooling took: {round(end_time-start_time,2)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IndustrialApplications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
