{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8cdc5a",
   "metadata": {},
   "source": [
    "# CNN Inference with NumPy\n",
    "In the classic CNN behaviour, we are given an image, the kernel passes over each subset of the image and for each subset it computes the sum of element-wise products. If done with vanilla Python, this procedure results in a slow execution. In PyTorch the problem is solved thanks to the framework given by the module itself. The idea of using numpy consists in transforming the given image in a matrix where each row is composed by one of the subset of the image interested in the convolution with the kernel, then vectorize the kernel and then perform the convolution step by simply operating a dot product between the subset and the kernel. This operation is fast in numpy, which is the Python module responsible for numeric computations. This approach is good but it introduces redundancy in data. A tradeoff between memory and cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842de893",
   "metadata": {},
   "source": [
    "# provare jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8cf62",
   "metadata": {},
   "source": [
    "`PLACEHOLDER`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b36d8b",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce4150",
   "metadata": {},
   "source": [
    "### Kernel Multiplication\n",
    "Convolving an image of dimensions 800 x 600 x 3 where 3 is the number of channels (one for red, one for green and one for blue) with a kernel of size 2x2x3 outputs an image of dimensions 799x599x1. Kernel's number of channels must match the number of channels of the input image. Therefore if i want, for example, to obtain a color image as the result of a convolution, i would need to convolve the input image with three kernels of three channels. Another way to see this is that the number of kernels i use in the convolution will become the number of channels for the output image \n",
    "\n",
    "`X = X[::3,:]` means \"Please select the first three rows of matrix X and return them\"\n",
    "\n",
    "### Channels Problem: How to consider multiple channels:\n",
    "taking the previous matrix as an example, and adding a channel where every number is the corresponding of the first channel but *100 we obtain:\n",
    "01,02,05,06,101,102,105,106\n",
    "Which means just append the next channel's corresponding flattened window to the previous one\n",
    "\n",
    "### Batch Problem: How to consider multiple images:\n",
    "just add the obtained windows at the end of the ones of the previous image, so instead of having a 5 rows 9 columns matrix of windows the result will be a matrix of 10 rows and 9 columns.\n",
    "\n",
    "### Final input management\n",
    "The more images can be stacked in the input, the faster the training will be, therefore the stack dimension must be taken into account. If the desire is to manage stacks of 8, 800x600 resolution color images (numbers were chosen so that they are better recognizable) with a 5x4 kernel, the function to create windows will have this shape:\n",
    "\n",
    "`X = np.random.rand(8*3*800*600).reshape(8,3,800,600)`\n",
    "\n",
    "`y = np.lib.stride_tricks.sliding_window_view(X,(1,3,5,4)).reshape(-1,(3*5*4))`\n",
    "\n",
    "Which translates in:\n",
    "\n",
    "`y = np.lib.stride_tricks.sliding_window_view(X,(1,CHANNEL_SIZE,KERNEL_WIDTH,KERNEL_HEIGHT))`\n",
    "\n",
    "`y = y.reshape(-1,(CHANNEL_SIZE*KERNEL_WIDTH*KERNEL_HEIGHT))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42f52d",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1739ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trials = True\n",
    "def tprint(value):\n",
    "    print(value) if trials else print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76440db3",
   "metadata": {},
   "source": [
    "### Inefficient Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPooling2DIneff(batch_of_images,win_size = 2, stride=2):\n",
    "    # very inefficient... but it works...\n",
    "    # it gives the same result as PyTorch's nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "    #print(batch_of_images.shape)\n",
    "    niw = round(iw/2) if iw % 2 == 0 else round(iw/2)-1\n",
    "    nih = round(ih/2) if ih % 2 == 0 else round(ih/2)-1\n",
    "    batch = []\n",
    "    for bb in range(bs):\n",
    "        channel=[]\n",
    "        for cc in range(nc):\n",
    "            y=[]\n",
    "            for i in range(0,ih,stride):\n",
    "                for j in range(0,iw,stride):\n",
    "                    if (j+win_size)>iw:\n",
    "                        continue\n",
    "                    if (i+win_size)>ih:\n",
    "                        continue\n",
    "                    y.append(batch_of_images[bb,cc,i:(i+win_size),j:(j+win_size)].max())\n",
    "            y=np.array(y).reshape(niw,nih)\n",
    "            channel.append(y)\n",
    "        batch.append(channel)\n",
    "    return np.array(batch)\n",
    "## this is an example\n",
    "#X = np.arange(1,(6*6*2*2)+1).reshape(2,2,6,6)\n",
    "#print(X)\n",
    "#r=MaxPooling2D(X)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee45ce",
   "metadata": {},
   "source": [
    "### Sliding Window View\n",
    "To implement the im2col convolution approach, the first thing to do is creating the matrix of windows from the given image. This can be done with the helpful function `np.lib.stride_tricks.sliding_window_view(image,kernel_shape)` which exactly returns what this approach needs. In the next panel the functioning of this function will be done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7d5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2  3]\n",
      "   [ 4  5  6]\n",
      "   [ 7  8  9]]\n",
      "\n",
      "  [[10 11 12]\n",
      "   [13 14 15]\n",
      "   [16 17 18]]]\n",
      "\n",
      "\n",
      " [[[19 20 21]\n",
      "   [22 23 24]\n",
      "   [25 26 27]]\n",
      "\n",
      "  [[28 29 30]\n",
      "   [31 32 33]\n",
      "   [34 35 36]]]]\n",
      "desired result\n",
      "[1,2,4,5]\n",
      "[2,3,5,6]\n",
      "...\n",
      "correct one:\n",
      "wrong: after the first window there is the first window of the channel\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,(2*2*3*3)+1).reshape(2,2,3,3)\n",
    "tprint(X)\n",
    "tprint(\"desired result\")\n",
    "tprint(\"[1,2,4,5]\")\n",
    "tprint(\"[2,3,5,6]\")\n",
    "tprint(\"...\")\n",
    "tprint(\"correct one:\")\n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,1,2,2))\n",
    "tprint(\"wrong: after the first window there is the first window of the channel\")\n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,1,2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965932c",
   "metadata": {},
   "source": [
    "### Back from Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13611bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 0. 4. 0.]\n",
      " [0. 0. 0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "X= np.zeros(4*4).reshape(4,4)\n",
    "values = np.array([1,2,3,4]).reshape(2,2)\n",
    "indices=np.array([0,1,3,2]).reshape(2,2)\n",
    "print(X)\n",
    "np.add.at(X,(indices,indices),values)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b832470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "row,col\n",
      "[1 0 1 0] [1 0 0 1]\n",
      "r_out_idx\n",
      "[[0 0]\n",
      " [1 1]]\n",
      "c_out_idx\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "vert_start\n",
      "[[0 0]\n",
      " [2 2]]\n",
      "horiz_start\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "idx_row_in_window_reshaped\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "idx_col_in_window_reshaped\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "abs_row_coords\n",
      "[[1 0]\n",
      " [3 2]]\n",
      "abs_col_coords\n",
      "[[1 2]\n",
      " [0 3]]\n",
      "back_X\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "back_X\n",
      "[[0. 0. 3. 0.]\n",
      " [0. 7. 0. 0.]\n",
      " [0. 0. 0. 5.]\n",
      " [4. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.arange(1,17).reshape(4,4)\n",
    "print(X)\n",
    "stride = winSize = 2\n",
    "small_X = np.array([6,5,6,7]).reshape(2,2)\n",
    "small_dX = np.array([7,3,4,5]).reshape(2,2)\n",
    "H_out,W_out = small_dX.shape\n",
    "ind = np.array([3,0,2,1])\n",
    "back_X = np.zeros(X.shape)\n",
    "row = ind // winSize # if [3,3,3,3] // 2 returns [1,1,1,1]\n",
    "col = ind % winSize # if [3,3,3,3] // 2 returns [1,1,1,1]\n",
    "print(\"row,col\")\n",
    "print(row,col)\n",
    "# it means, the first element must be at row one and col one starting from zero.\n",
    "r_out_idx, c_out_idx = np.indices((H_out, W_out))\n",
    "print(\"r_out_idx\")\n",
    "print(r_out_idx)\n",
    "print(\"c_out_idx\")\n",
    "print(c_out_idx)\n",
    "\n",
    "vert_start = r_out_idx * stride # Forma (bs, nc, H_out, W_out)\n",
    "horiz_start = c_out_idx * stride # Forma (bs, nc, H_out, W_out)\n",
    "print(\"vert_start\")\n",
    "print(vert_start)\n",
    "print(\"horiz_start\")\n",
    "print(horiz_start)\n",
    "#    c. Calcola le coordinate assolute finali in dA_prev\n",
    "#       idx_row_in_window e idx_col_in_window devono essere \"broadcastabili\" o\n",
    "#       avere la stessa forma di vert_start e horiz_start se non sono già piatte.\n",
    "#       Poiché indices_flat era (bs*nc*H_out*W_out,), rimodelliamoli:\n",
    "idx_row_in_window_reshaped = row.reshape(H_out, W_out)\n",
    "idx_col_in_window_reshaped = col.reshape(H_out, W_out)\n",
    "print(\"idx_row_in_window_reshaped\")\n",
    "print(idx_row_in_window_reshaped)\n",
    "print(\"idx_col_in_window_reshaped\")\n",
    "print(idx_col_in_window_reshaped)\n",
    "abs_row_coords = vert_start + idx_row_in_window_reshaped # Forma (bs, nc, H_out, W_out)\n",
    "abs_col_coords = horiz_start + idx_col_in_window_reshaped # Forma (bs, nc, H_out, W_out)\n",
    "print(\"abs_row_coords\")\n",
    "print(abs_row_coords)\n",
    "print(\"abs_col_coords\")\n",
    "print(abs_col_coords)\n",
    "# 4. Usa np.add.at per sommare i gradienti d_out nelle posizioni calcolate di dA_prev.\n",
    "#    np.add.at(array, indici, valori_da_aggiungere)\n",
    "#    Gli 'indici' devono essere una tupla di array di indici per ogni dimensione.\n",
    "#    Tutti gli array in 'indici' e 'valori_da_aggiungere' devono essere broadcastabili\n",
    "#    a una forma comune, o essere appiattiti in modo consistente.\n",
    "\n",
    "#    Creiamo gli indici per np.add.at:\n",
    "#    Tutti questi array (b_idx, ch_idx, abs_row_coords, abs_col_coords, d_out)\n",
    "#    hanno già la stessa forma (bs, nc, H_out, W_out), quindi NumPy\n",
    "#    li gestirà elemento per elemento quando usati come indici e valori.\n",
    "\n",
    "indices_for_add_at = (\n",
    "    abs_row_coords,         # Indici per la dimensione altezza di dA_prev\n",
    "    abs_col_coords          # Indici per la dimensione larghezza di dA_prev\n",
    ")\n",
    "print(\"back_X\")\n",
    "print(back_X)\n",
    "np.add.at(back_X, indices_for_add_at, small_dX)\n",
    "print(\"back_X\")\n",
    "print(back_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93155ee2",
   "metadata": {},
   "source": [
    "### Striding\n",
    "The next panel is devoted to explore the striding, achieved using the preceding, function along with the `[:,:,::2,::2]` construct that, respectively, leaves untouched the number of images in the batch and the number of channels, but selects one row every two and one column every two. rows and columns after the sliding window, uniquely identify one window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedbc941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]\n",
      "   [ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]\n",
      "   [25 26 27 28]\n",
      "   [29 30 31 32]]]]\n",
      "[[ 1  2  5  6]\n",
      " [17 18 21 22]\n",
      " [ 3  4  7  8]\n",
      " [19 20 23 24]\n",
      " [ 9 10 13 14]\n",
      " [25 26 29 30]\n",
      " [11 12 15 16]\n",
      " [27 28 31 32]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,16*2+1).reshape(1,2,4,4)\n",
    "tprint(X)\n",
    "# basically [::2,::2] selects every two rows and every two columns, where in this case elements are 3 dimensional matrices of 2 by 2 so the \n",
    "# selection eliminates the desired elements, resulting in a stride 2 convolution \n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,2,2,2))[:,:,::2,::2]\n",
    "#y = np.lib.stride_tricks.as_strided(X,shape=(2,2),strides=[1,2,3,4])\n",
    "tprint(y.reshape(-1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087d69f",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b40418",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e55bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7da90c",
   "metadata": {},
   "source": [
    "### Loading images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8634158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Leggi intestazione: magic number, numero immagini, righe, colonne\n",
    "        magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        # Leggi tutti i pixel e convertili in array numpy\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        # Ridimensiona l'array in (num_images, rows, cols)\n",
    "        images = images.reshape((num_images, rows, cols))\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "images = load_mnist_images('MNIST/train-images-idx3-ubyte')\n",
    "labels = load_mnist_labels('MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "print(images.shape)  # (60000, 28, 28)\n",
    "print(labels.shape)  # (60000,)\n",
    "one_hot_labels = np.zeros(labels.shape[0]*10).reshape((labels.shape[0]),10)\n",
    "for i in range(len(labels)):\n",
    "    one_hot_labels[i][labels[i]]=1\n",
    "labels = one_hot_labels\n",
    "print(labels.shape) # (60000,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89060d9",
   "metadata": {},
   "source": [
    "CNN Structure\n",
    "The goal is achieving over 90% of accuracy with a simple structure, therefore this would be the set of layers:\n",
    "- Convolutional Layer with 32 2x2 filters and ReLU activation: i: (B x C X 28 x 28), o: (B x 32 x 26 x 26)\n",
    "- Max Pooling layer with 2x2 filter: i: (B x 32 x 26 x 26), o: (B x 32 x 13 x 13)\n",
    "- Convolutional Layer with 32 2x2 filters and ReLU activation: i: (B x 13 x 13 x 32), o: (B x 11 x 11 x 64)\n",
    "- Linear Fully Connected Layer with ReLU activation: i: (B x 7744), o: (B x 250)\n",
    "- Linear Fully Connected Layer with Softmax activation: i: (B x 250), o: (B x 10)\n",
    "- Cross-Entropy Loss: -sum(true_probability_distribution*log(predicted_probability_distribution))\n",
    "\n",
    "where B is the batch_size and C is the number of channels, that for MNIST digits is just one, since they are greyscale images.\n",
    "\n",
    "The idea is to reduce everything to a matrix-matrix multiplication which is super fast in NumPy, an optimized mathematical module for Python, by taking an image and create a matrix containing for each row the flattened window that would enter the convolution, as an example:\n",
    "the first 2 flattened windows of this matrix:\n",
    "01,02,03,04\n",
    "05,06,07,08\n",
    "09,10,11,12\n",
    "13,14,15,16\n",
    "for a kernel 2x2 of stride 1 are:\n",
    "01,02,05,06\n",
    "02,03,06,07\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af530dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [4 2]]\n",
      "[[0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([-4,0,4,2]).reshape(2,2)\n",
    "reluX = np.maximum(0,X)\n",
    "print(reluX)\n",
    "BReluX=reluX\n",
    "BReluX[BReluX>0]=1\n",
    "print(BReluX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d8c65f",
   "metadata": {},
   "source": [
    "## CNN - PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from tqdm import tqdm # tqdm standard può funzionare qui, ma tqdm.notebook è per jupyter\n",
    "\n",
    "# # --- 1. Definizione del Modello ---\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # --- Layer Convoluzionali ---\n",
    "        # Input: (bs, 1, 28, 28)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        # Output: (bs, 32, 14, 14) -> floor((28-3+2*1)/2)+1 = 14\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        # Output: (bs, 64, 7, 7) -> floor((14-3+2*1)/2)+1 = 7\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
    "        # Output: (bs, 128, 4, 4) -> floor((7-3+2*1)/2)+1 = 4\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # --- Flattening ---\n",
    "        self.flatten = nn.Flatten() # Converte (bs, C, H, W) in (bs, C*H*W)\n",
    "\n",
    "        # Calcolo dimensione flatten: 128 * 4 * 4 = 2048\n",
    "        fc_input_size = 128 * 4 * 4\n",
    "\n",
    "        # --- Layer Fully Connected (MLP) ---\n",
    "        self.fc1 = nn.Linear(in_features=fc_input_size, out_features=250)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=250, out_features=num_classes)\n",
    "        # Nota: nn.CrossEntropyLoss applica Softmax internamente, quindi non è necessario qui.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Blocco convoluzionale 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # Blocco convoluzionale 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        # Blocco convoluzionale 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = self.flatten(x) # Ora x ha shape (bs, 2048)\n",
    "\n",
    "        # MLP\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x) # Output sono i logits (raw scores)\n",
    "\n",
    "        return x\n",
    "\n",
    "# # --- 2. Preparazione Dati (MNIST) ---\n",
    "\n",
    "# # Trasformazioni per il dataset MNIST\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(), # Converte l'immagine in Tensor PyTorch e scala a [0, 1]\n",
    "#     transforms.Normalize((0.1307,), (0.3081,)) # Normalizzazione standard per MNIST\n",
    "# ])\n",
    "\n",
    "# # Scarica e carica il dataset di training\n",
    "# train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "# # Scarica e carica il dataset di test (o validazione)\n",
    "# test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# # Crea i DataLoader per gestire i batch\n",
    "# batch_size = 64 # Puoi aggiustare il batch size\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# # --- 3. Setup Training ---\n",
    "\n",
    "# # Seleziona il device (GPU se disponibile, altrimenti CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Utilizzo del device: {device}\")\n",
    "\n",
    "# # Istanzia il modello e spostalo sul device\n",
    "# model = SimpleCNN(num_classes=10).to(device)\n",
    "# print(model) # Stampa la struttura del modello\n",
    "\n",
    "# # Definisci la funzione di loss\n",
    "# criterion = nn.CrossEntropyLoss() # Combina LogSoftmax e NLLLoss\n",
    "\n",
    "# # Definisci l'ottimizzatore\n",
    "# learning_rate = 0.001\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Numero di epoche\n",
    "# num_epochs = 5 # Puoi aumentarlo per un training più lungo\n",
    "\n",
    "# # --- 4. Ciclo di Training ---\n",
    "\n",
    "# print(\"\\nInizio Training...\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train() # Imposta il modello in modalità training\n",
    "#     running_loss = 0.0\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Usa tqdm per la barra di progresso\n",
    "#     progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "\n",
    "#     for inputs, labels in progress_bar:\n",
    "#         # Sposta i dati sul device\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "#         # Azzera i gradienti dell'ottimizzatore\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # Forward pass\n",
    "#         outputs = model(inputs) # Ottieni i logits\n",
    "\n",
    "#         # Calcola la loss\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         # Backward pass (calcolo gradienti)\n",
    "#         loss.backward()\n",
    "\n",
    "#         # Aggiorna i pesi\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # Aggiorna la loss corrente per il logging\n",
    "#         running_loss += loss.item() * inputs.size(0) # Moltiplica per il batch size per la media corretta\n",
    "\n",
    "#         # Aggiorna la descrizione della barra di progresso\n",
    "#         progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "#     # Calcola la loss media dell'epoca\n",
    "#     epoch_loss = running_loss / len(train_loader.dataset)\n",
    "#     epoch_time = time.time() - start_time\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs} - Tempo: {epoch_time:.2f}s - Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "#     # --- Valutazione sul Test Set (dopo ogni epoca) ---\n",
    "#     model.eval() # Imposta il modello in modalità valutazione\n",
    "#     test_loss = 0.0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "\n",
    "#     with torch.no_grad(): # Disabilita il calcolo dei gradienti per la valutazione\n",
    "#         for inputs, labels in test_loader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             outputs = model(inputs) # Logits\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "#             _, predicted = torch.max(outputs.data, 1) # Ottieni l'indice della classe con probabilità massima\n",
    "#             total += labels.size(0)\n",
    "#             correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "#     accuracy = 100 * correct / total\n",
    "#     print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f} - Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# print(\"\\nTraining Completato.\")\n",
    "\n",
    "# # (Opzionale) Salvare il modello addestrato\n",
    "# torch.save(model.state_dict(), 'simple_cnn_mnist.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estrazione Pesi e Bias...\n",
      "\n",
      "k1: PyTorch Shape=(32, 1, 3, 3), NumPy Shape=(1, 32, 3, 3)\n",
      "b_conv1: NumPy Shape=(32,)\n",
      "k2: PyTorch Shape=(64, 32, 3, 3), NumPy Shape=(32, 64, 3, 3)\n",
      "b_conv2: NumPy Shape=(64,)\n",
      "k3: PyTorch Shape=(128, 64, 3, 3), NumPy Shape=(64, 128, 3, 3)\n",
      "b_conv3: NumPy Shape=(128,)\n",
      "w1: PyTorch Shape=(250, 2048), NumPy Shape=(2048, 250)\n",
      "b1: PyTorch Shape=(250,), NumPy Shape=(1, 250)\n",
      "w2: PyTorch Shape=(10, 250), NumPy Shape=(250, 10)\n",
      "b2: PyTorch Shape=(10,), NumPy Shape=(1, 10)\n",
      "\n",
      "Estrazione completata. I pesi NumPy sono nel dizionario 'numpy_weights'.\n"
     ]
    }
   ],
   "source": [
    "# Assumi che 'SimpleCNN' sia la classe del modello definita precedentemente\n",
    "# e 'model' sia un'istanza addestrata di SimpleCNN.\n",
    "\n",
    "# Esempio: Carica un modello addestrato (se l'hai salvato)\n",
    "model = SimpleCNN(num_classes=10)\n",
    "model.load_state_dict(torch.load('simple_cnn_mnist.pth', map_location=torch.device('cpu'))) # Carica su CPU\n",
    "\n",
    "# Assicurati che il modello sia in modalità valutazione (non strettamente necessario\n",
    "# per estrarre i pesi, ma buona pratica)\n",
    "model.eval()\n",
    "\n",
    "# --- Estrazione Parametri e Conversione in NumPy ---\n",
    "\n",
    "# Dizionario per contenere i pesi NumPy\n",
    "numpy_weights = {}\n",
    "\n",
    "# Sposta il modello su CPU se è su GPU, prima di chiamare .numpy()\n",
    "model.to('cpu')\n",
    "\n",
    "print(\"Estrazione Pesi e Bias...\\n\")\n",
    "\n",
    "# Layer Conv1\n",
    "# PyTorch weight shape: (out_channels, in_channels, kernel_height, kernel_width)\n",
    "# NumPy atteso (basato sul codice precedente): (in_channels, out_channels, kernel_width, kernel_height) -> (1, 32, 3, 3)\n",
    "pyt_k1_w = model.conv1.weight.data.detach().numpy()\n",
    "# Trasponi: (out, in, kH, kW) -> (in, out, kW, kH)\n",
    "numpy_weights['k1'] = pyt_k1_w.transpose(1, 0, 3, 2)\n",
    "# PyTorch bias shape: (out_channels,)\n",
    "numpy_weights['b_conv1'] = model.conv1.bias.data.detach().numpy() # Shape (32,)\n",
    "print(f\"k1: PyTorch Shape={pyt_k1_w.shape}, NumPy Shape={numpy_weights['k1'].shape}\")\n",
    "print(f\"b_conv1: NumPy Shape={numpy_weights['b_conv1'].shape}\")\n",
    "\n",
    "# Layer Conv2\n",
    "# PyTorch weight shape: (64, 32, 3, 3)\n",
    "# NumPy atteso: (32, 64, 3, 3)\n",
    "pyt_k2_w = model.conv2.weight.data.detach().numpy()\n",
    "numpy_weights['k2'] = pyt_k2_w.transpose(1, 0, 3, 2)\n",
    "numpy_weights['b_conv2'] = model.conv2.bias.data.detach().numpy() # Shape (64,)\n",
    "print(f\"k2: PyTorch Shape={pyt_k2_w.shape}, NumPy Shape={numpy_weights['k2'].shape}\")\n",
    "print(f\"b_conv2: NumPy Shape={numpy_weights['b_conv2'].shape}\")\n",
    "\n",
    "# Layer Conv3\n",
    "# PyTorch weight shape: (128, 64, 3, 3)\n",
    "# NumPy atteso: (64, 128, 3, 3)\n",
    "pyt_k3_w = model.conv3.weight.data.detach().numpy()\n",
    "numpy_weights['k3'] = pyt_k3_w.transpose(1, 0, 3, 2)\n",
    "numpy_weights['b_conv3'] = model.conv3.bias.data.detach().numpy() # Shape (128,)\n",
    "print(f\"k3: PyTorch Shape={pyt_k3_w.shape}, NumPy Shape={numpy_weights['k3'].shape}\")\n",
    "print(f\"b_conv3: NumPy Shape={numpy_weights['b_conv3'].shape}\")\n",
    "\n",
    "# Layer FC1\n",
    "# PyTorch weight shape: (out_features, in_features) -> (250, 2048)\n",
    "# NumPy atteso (per input @ W): (in_features, out_features) -> (2048, 250)\n",
    "pyt_w1 = model.fc1.weight.data.detach().numpy()\n",
    "numpy_weights['w1'] = pyt_w1.T # Trasponi\n",
    "# PyTorch bias shape: (out_features,) -> (250,)\n",
    "# NumPy atteso (per aggiunta diretta): (1, out_features) -> (1, 250)\n",
    "pyt_b1 = model.fc1.bias.data.detach().numpy()\n",
    "numpy_weights['b1'] = pyt_b1.reshape(1, -1) # Rendi (1, 250)\n",
    "print(f\"w1: PyTorch Shape={pyt_w1.shape}, NumPy Shape={numpy_weights['w1'].shape}\")\n",
    "print(f\"b1: PyTorch Shape={pyt_b1.shape}, NumPy Shape={numpy_weights['b1'].shape}\")\n",
    "\n",
    "# Layer FC2\n",
    "# PyTorch weight shape: (num_classes, 250) -> (10, 250)\n",
    "# NumPy atteso: (250, num_classes) -> (250, 10)\n",
    "pyt_w2 = model.fc2.weight.data.detach().numpy()\n",
    "numpy_weights['w2'] = pyt_w2.T # Trasponi\n",
    "# PyTorch bias shape: (num_classes,) -> (10,)\n",
    "# NumPy atteso: (1, num_classes) -> (1, 10)\n",
    "pyt_b2 = model.fc2.bias.data.detach().numpy()\n",
    "numpy_weights['b2'] = pyt_b2.reshape(1, -1) # Rendi (1, 10)\n",
    "print(f\"w2: PyTorch Shape={pyt_w2.shape}, NumPy Shape={numpy_weights['w2'].shape}\")\n",
    "print(f\"b2: PyTorch Shape={pyt_b2.shape}, NumPy Shape={numpy_weights['b2'].shape}\")\n",
    "\n",
    "print(\"\\nEstrazione completata. I pesi NumPy sono nel dizionario 'numpy_weights'.\")\n",
    "\n",
    "# Ora puoi usare numpy_weights['k1'], numpy_weights['k2'], ecc. nella tua\n",
    "# implementazione NumPy per l'inferenza.\n",
    "\n",
    "# Esempio di accesso:\n",
    "np_k1 = numpy_weights['k1']\n",
    "np_k2 = numpy_weights['k2']\n",
    "np_k3 = numpy_weights['k3']\n",
    "np_w1 = numpy_weights['w1']\n",
    "np_b1 = numpy_weights['b1']\n",
    "np_w2 = numpy_weights['w2']\n",
    "np_b2 = numpy_weights['b2']\n",
    "\n",
    "\n",
    "# !!! ATTENZIONE AI BIAS CONVOLUZIONALI !!!\n",
    "# Ho estratto anche i bias dei layer convoluzionali (b_conv1, b_conv2, b_conv3).\n",
    "# La tua implementazione NumPy originale di ReLU_ConvolutionS NON includeva\n",
    "# l'aggiunta del bias dopo la somma pesata.\n",
    "# Se vuoi usare questi bias, dovrai modificare la tua funzione NumPy\n",
    "# ReLU_ConvolutionS per aggiungere il bias corrispondente a ogni canale di output\n",
    "# PRIMA di applicare la ReLU. Esempio (pseudo-codice all'interno di ReLU_ConvolutionS):\n",
    "# ... dopo aver calcolato current_sum per la posizione (i_bs, i_kc, i_nih, i_niw) ...\n",
    "# current_sum_with_bias = current_sum + bias_conv[i_kc] # bias_conv sarebbero b_conv1/2/3\n",
    "# ni[i_bs, i_kc, i_nih, i_niw] = np.maximum(0, current_sum_with_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f1b9289d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 250)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_weights[\"b1\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c4d4f",
   "metadata": {},
   "source": [
    "## CNN - Slow Implementation\n",
    "\n",
    "This implementation utilizes four nested loops to compute the convolutions. Each one represents one dimension: batch, channels, width and height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb324f",
   "metadata": {},
   "source": [
    "### Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68bb6da",
   "metadata": {},
   "source": [
    "#### With Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ReLU_ConvolutionS(boi, k, b_conv, p=0, s=1):\n",
    "    \"\"\"\n",
    "    Calcola la convoluzione 2D + Bias + ReLU con cicli for.\n",
    "\n",
    "    Args:\n",
    "        boi (np.ndarray): Batch di immagini input (bs, nc, ih, iw).\n",
    "        k (np.ndarray):   Kernel (ac, kc, kw, kh). Assumendo ac=nc.\n",
    "        b_conv (np.ndarray): Bias per i canali di output. Shape (kc,).\n",
    "        p (int):           Padding.\n",
    "        s (int):           Stride.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Output attivato (bs, kc, nih, niw).\n",
    "    \"\"\"\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, ih, iw = boi.shape\n",
    "\n",
    "    if b_conv.shape[0] != kc:\n",
    "        raise ValueError(f\"La dimensione del bias ({b_conv.shape[0]}) non corrisponde al numero di canali di output ({kc})\")\n",
    "    if ac != nc:\n",
    "         raise ValueError(f\"Il numero di canali del kernel ({ac}) deve corrispondere al numero di canali dell'immagine ({nc})\")\n",
    "\n",
    "    # Usa int() per le dimensioni output\n",
    "    nih = int(((ih - kh + (2 * p)) / s) + 1) # new image height\n",
    "    niw = int(((iw - kw + (2 * p)) / s) + 1) # new image width\n",
    "    ni = np.zeros((bs, kc, nih, niw)) # new image\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            # Ottieni il bias per questo canale di output\n",
    "            current_bias = b_conv[i_kc]\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    current_sum = 0.0 # Somma solo convoluzione\n",
    "                    # Cicli per la convoluzione\n",
    "                    for i_nc in range(nc):\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "                                # Controlla limiti per padding implicito\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    input_val = boi[i_bs, i_nc, input_y, input_x]\n",
    "                                    kernel_val = k[i_nc, i_kc, i_kw, i_kh]\n",
    "                                    current_sum += input_val * kernel_val\n",
    "\n",
    "                    # --- Aggiungi Bias e Applica ReLU ---\n",
    "                    activation_input = current_sum + current_bias\n",
    "                    ni[i_bs, i_kc, i_nih, i_niw] = np.maximum(0, activation_input)\n",
    "\n",
    "    return ni\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "def ReLU_ConvolutionS_backward(d_ni, boi, k, b_conv, ni_forward, p=0, s=1):\n",
    "    \"\"\"\n",
    "    Calcola la backpropagation per ReLU_ConvolutionS (con Bias).\n",
    "\n",
    "    Args:\n",
    "        d_ni (np.ndarray): Gradiente Loss rispetto output (bs, kc, nih, niw).\n",
    "        boi (np.ndarray):  Input batch originale (bs, nc, ih, iw).\n",
    "        k (np.ndarray):    Kernel originali (ac, kc, kw, kh).\n",
    "        b_conv (np.ndarray): Bias originali. Shape (kc,).\n",
    "        ni_forward (np.ndarray): Output originale forward pass (bs, kc, nih, niw).\n",
    "        p (int):           Padding.\n",
    "        s (int):           Stride.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray, np.ndarray]: Una tupla contenente:\n",
    "            - d_boi (np.ndarray): Gradiente Loss rispetto input 'boi'.\n",
    "            - d_k (np.ndarray):   Gradiente Loss rispetto kernel 'k'.\n",
    "            - d_b_conv (np.ndarray): Gradiente Loss rispetto bias 'b_conv'.\n",
    "    \"\"\"\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, ih, iw = boi.shape\n",
    "    bs_out, kc_out, nih, niw = d_ni.shape\n",
    "\n",
    "    if b_conv.shape[0] != kc:\n",
    "        raise ValueError(f\"La dimensione del bias ({b_conv.shape[0]}) non corrisponde al numero di canali di output ({kc})\")\n",
    "    if (bs, kc, nih, niw) != ni_forward.shape:\n",
    "        raise ValueError(\"Le dimensioni di d_ni non corrispondono a quelle di ni_forward.\")\n",
    "    if ac != nc:\n",
    "         raise ValueError(f\"Il numero di canali del kernel ({ac}) deve corrispondere al numero di canali dell'immagine ({nc})\")\n",
    "\n",
    "    # Inizializza i gradienti\n",
    "    d_boi = np.zeros_like(boi)\n",
    "    d_k = np.zeros_like(k)\n",
    "    d_b_conv = np.zeros_like(b_conv) # Gradiente per il bias, shape (kc,)\n",
    "\n",
    "    # Backprop attraverso ReLU: dL/d(somma+bias)\n",
    "    d_activation_input = d_ni * (ni_forward > 0) # Shape (bs, kc, nih, niw)\n",
    "\n",
    "    # Calcolo gradienti\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    # Gradiente che arriva a questo punto (prima della somma e bias)\n",
    "                    grad_curr = d_activation_input[i_bs, i_kc, i_nih, i_niw]\n",
    "\n",
    "                    # Se il gradiente è zero, non c'è contributo\n",
    "                    if grad_curr == 0:\n",
    "                        continue\n",
    "\n",
    "                    # --- Accumula Gradiente per il Bias ---\n",
    "                    # dL/db = dL/d(somma+bias) * d(somma+bias)/db\n",
    "                    # d(somma+bias)/db = 1\n",
    "                    # Quindi dL/db = dL/d(somma+bias) = grad_curr\n",
    "                    # Sommiamo su bs, nih, niw per ogni kc\n",
    "                    d_b_conv[i_kc] += grad_curr\n",
    "\n",
    "                    # --- Accumula Gradienti per Kernel (d_k) e Input (d_boi) ---\n",
    "                    # Questi calcoli rimangono invariati perché il bias\n",
    "                    # viene aggiunto *dopo* la moltiplicazione input*kernel.\n",
    "                    # Usiamo lo stesso grad_curr (dL/d(somma+bias)).\n",
    "                    for i_nc in range(nc): # nc == ac\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "                                # Controlla limiti\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    # dL/dk += dL/d(somma+bias) * d(somma)/dk\n",
    "                                    d_k[i_nc, i_kc, i_kw, i_kh] += grad_curr * boi[i_bs, i_nc, input_y, input_x]\n",
    "                                    # dL/dboi += dL/d(somma+bias) * d(somma)/dboi\n",
    "                                    d_boi[i_bs, i_nc, input_y, input_x] += grad_curr * k[i_nc, i_kc, i_kw, i_kh]\n",
    "\n",
    "    # Restituisci tutti i gradienti calcolati\n",
    "    return d_boi, d_k, d_b_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded4107",
   "metadata": {},
   "source": [
    "#### With Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eecf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_ConvolutionS(boi,k,p=0,s=1):\n",
    "    #boi stands for batch of images and has these dimensions: Batch_size, Number of Channels, Width, Height.\n",
    "    #k stands for kernel and has these dimensions: Input images' number of channels, number of kernels, Width, Height\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, iw, ih = boi.shape\n",
    "    niw = round(((iw-kw+(2*p))/s)+1) # new image width\n",
    "    nih = round(((ih-kh+(2*p))/s)+1) # new image height\n",
    "    ni= np.zeros(bs*kc*niw*nih).reshape(bs,kc,niw,nih) # new image\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    current_sum = 0.0\n",
    "                    for i_nc in range(nc):\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    input_val = boi[i_bs, i_nc, input_y, input_x]\n",
    "                                    # Ottieni il peso corrispondente dal kernel\n",
    "                                    # Indici kernel: [canale_input, indice_kernel_output, indice_larghezza, indice_altezza]\n",
    "                                    # secondo l'unpack kw, kh = k.shape[2], k.shape[3]\n",
    "                                    kernel_val = k[i_nc, i_kc, i_kw, i_kh]\n",
    "                                    # Moltiplica e accumula\n",
    "                                    current_sum += input_val * kernel_val\n",
    "                    ni[i_bs, i_kc, i_nih, i_niw] = np.maximum(0, current_sum)\n",
    "    return ni\n",
    "\n",
    "def ReLU_ConvolutionS_backward(d_ni, boi, k, ni_forward, p=0, s=1):\n",
    "    \"\"\"\n",
    "    Calcola la backpropagation per la funzione ReLU_ConvolutionS.\n",
    "\n",
    "    Args:\n",
    "        d_ni (np.ndarray): Gradiente della Loss rispetto all'output della convoluzione (ni).\n",
    "                           Dimensioni: (bs, kc, nih, niw).\n",
    "        boi (np.ndarray):  Input batch originale della forward pass.\n",
    "                           Dimensioni: (bs, nc, ih, iw).\n",
    "        k (np.ndarray):    Kernel originali della forward pass.\n",
    "                           Dimensioni: (ac, kc, kw, kh) dove ac=nc.\n",
    "        ni_forward (np.ndarray): Output originale della forward pass (prima del gradiente).\n",
    "                                 Necessario per il gradiente della ReLU.\n",
    "                                 Dimensioni: (bs, kc, nih, niw).\n",
    "        p (int):           Padding usato nella forward pass.\n",
    "        s (int):           Stride usato nella forward pass.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: Una tupla contenente:\n",
    "            - d_boi (np.ndarray): Gradiente della Loss rispetto all'input batch 'boi'.\n",
    "                                  Dimensioni: (bs, nc, ih, iw).\n",
    "            - d_k (np.ndarray):   Gradiente della Loss rispetto ai kernel 'k'.\n",
    "                                  Dimensioni: (ac, kc, kw, kh).\n",
    "    \"\"\"\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, ih, iw = boi.shape\n",
    "    bs_out, kc_out, nih, niw = d_ni.shape # Le dimensioni di d_ni devono corrispondere a ni_forward\n",
    "\n",
    "    if (bs, kc, nih, niw) != ni_forward.shape:\n",
    "        raise ValueError(\"Le dimensioni di d_ni non corrispondono a quelle di ni_forward.\")\n",
    "    if ac != nc:\n",
    "         raise ValueError(f\"Il numero di canali del kernel ({ac}) deve corrispondere al numero di canali dell'immagine ({nc})\")\n",
    "\n",
    "    # Inizializza i gradienti a zero\n",
    "    d_boi = np.zeros_like(boi)\n",
    "    d_k = np.zeros_like(k)\n",
    "\n",
    "    # --- Backpropagation attraverso ReLU ---\n",
    "    # Il gradiente passa solo dove l'output della ReLU (ni_forward) era > 0.\n",
    "    # dL/d(current_sum) = dL/dni * dni/d(current_sum)\n",
    "    #                   = d_ni * (1 if current_sum > 0 else 0)\n",
    "    #                   = d_ni * (1 if ni_forward > 0 else 0)\n",
    "    d_current_sum = d_ni * (ni_forward > 0) # Element-wise multiplication\n",
    "\n",
    "    # --- Calcolo dei Gradienti d_boi e d_k ---\n",
    "    # Iteriamo attraverso gli elementi del gradiente d_current_sum (o d_ni dopo ReLU)\n",
    "    # e propaghiamo il gradiente indietro a d_boi e d_k.\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    # Gradiente locale per questa posizione dell'output\n",
    "                    grad_curr = d_current_sum[i_bs, i_kc, i_nih, i_niw]\n",
    "\n",
    "                    # Se il gradiente è zero, non contribuisce ai gradienti precedenti\n",
    "                    if grad_curr == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Propagazione indietro: iteriamo sulla finestra di input/kernel\n",
    "                    # che ha contribuito a questo output\n",
    "                    for i_nc in range(nc): # nc == ac\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "\n",
    "                                # Verifica se l'input corrispondente era valido (dentro i limiti)\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    # --- Calcolo d_k ---\n",
    "                                    # dL/dk = dL/d(current_sum) * d(current_sum)/dk\n",
    "                                    # d(current_sum)/dk[c,kc,kw,kh] = boi[bs,c,y_in,x_in]\n",
    "                                    # L'indice del kernel è (i_nc, i_kc, i_kw, i_kh)\n",
    "                                    # L'indice dell'input è (i_bs, i_nc, input_y, input_x)\n",
    "                                    d_k[i_nc, i_kc, i_kw, i_kh] += grad_curr * boi[i_bs, i_nc, input_y, input_x]\n",
    "\n",
    "                                    # --- Calcolo d_boi ---\n",
    "                                    # dL/dboi = dL/d(current_sum) * d(current_sum)/dboi\n",
    "                                    # d(current_sum)/dboi[bs,c,y_in,x_in] = k[c,kc,kw,kh]\n",
    "                                    # L'indice dell'input è (i_bs, i_nc, input_y, input_x)\n",
    "                                    # L'indice del kernel è (i_nc, i_kc, i_kw, i_kh)\n",
    "                                    d_boi[i_bs, i_nc, input_y, input_x] += grad_curr * k[i_nc, i_kc, i_kw, i_kh]\n",
    "\n",
    "    return d_boi, d_k\n",
    "\n",
    "\n",
    "\n",
    "# X=np.arange(1,2*4*4+1).reshape(1,2,4,4)\n",
    "# k = np.ones(1*2*2*2).reshape(2,1,2,2)\n",
    "# print(\"X\")\n",
    "# print(X)\n",
    "# print(\"k\")\n",
    "# print(k)\n",
    "# X_c = ReLU_ConvolutionS(X,k,s=2)\n",
    "# print(\"X_c\")\n",
    "# print(X_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc7fc72",
   "metadata": {},
   "source": [
    "#### No Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cee29c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_ConvolutionS(boi,k,p=0,s=1):\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, iw, ih = boi.shape\n",
    "    niw = round(((iw-kw+(2*p))/s)+1) # new image width\n",
    "    nih = round(((ih-kh+(2*p))/s)+1) # new image height\n",
    "    ni= np.zeros(bs*kc*niw*nih).reshape(bs,kc,niw,nih) # new image\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    current_sum = 0.0\n",
    "                    for i_nc in range(nc):\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    input_val = boi[i_bs, i_nc, input_y, input_x]\n",
    "                                    kernel_val = k[i_nc, i_kc, i_kw, i_kh]\n",
    "                                    current_sum += input_val * kernel_val\n",
    "                    ni[i_bs, i_kc, i_nih, i_niw] = np.maximum(0, current_sum)\n",
    "    return ni\n",
    "\n",
    "def ReLU_ConvolutionS_backward(d_ni, boi, k, ni_forward, p=0, s=1):\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, ih, iw = boi.shape\n",
    "    bs_out, kc_out, nih, niw = d_ni.shape \n",
    "\n",
    "    if (bs, kc, nih, niw) != ni_forward.shape:\n",
    "        raise ValueError(\"Le dimensioni di d_ni non corrispondono a quelle di ni_forward.\")\n",
    "    if ac != nc:\n",
    "         raise ValueError(f\"Il numero di canali del kernel ({ac}) deve corrispondere al numero di canali dell'immagine ({nc})\")\n",
    "\n",
    "    d_boi = np.zeros_like(boi)\n",
    "    d_k = np.zeros_like(k)\n",
    "\n",
    "    d_current_sum = d_ni * (ni_forward > 0)\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    grad_curr = d_current_sum[i_bs, i_kc, i_nih, i_niw]\n",
    "                    if grad_curr == 0:\n",
    "                        continue\n",
    "                    for i_nc in range(nc): # nc == ac\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    d_k[i_nc, i_kc, i_kw, i_kh] += grad_curr * boi[i_bs, i_nc, input_y, input_x]\n",
    "                                    d_boi[i_bs, i_nc, input_y, input_x] += grad_curr * k[i_nc, i_kc, i_kw, i_kh]\n",
    "\n",
    "    return d_boi, d_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba912c0",
   "metadata": {},
   "source": [
    "### MLP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d45f3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,axis=-1,keepdims=True))  # for numerical stability\n",
    "    return e_x / np.sum(e_x,axis=-1,keepdims=True)\n",
    "\n",
    "def ReLU_SoftMax_FullyConnected(input_array,w1,b1,w2,b2):\n",
    "    fl = (input_array @ w1)+b1 # first layer\n",
    "    fa = np.maximum(0,fl) # first activation: ReLU\n",
    "    sl = (fa @ w2)+b2 # second layer\n",
    "    sa = softmax(sl) # second activation: SoftMax\n",
    "    return fl,fa,sl,sa\n",
    "\n",
    "#print(softmax([1,2,3,100000]))\n",
    "#print(softmax_no_NS([1,2,3,1000]))\n",
    "#r = np.array(np.array([1,2,777,2]))\n",
    "#print(softmax(r))\n",
    "#r = np.array((np.array([1,2,777,2]),np.array([1,2,777,2]),np.array([1,2,777,2])))\n",
    "#print(softmax(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55bd88",
   "metadata": {},
   "source": [
    "### Loss Function: Categorical Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8e51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(p,t):\n",
    "    # p stands for prediction and t stands for true label\n",
    "    # p = [0,0,1] and t = [1,0,0]\n",
    "    p = p+(1/100000) # for numerical stability\n",
    "    return -np.dot(t,np.log(p).T)\n",
    "\n",
    "#c = [1,1000000000000000,1,1]\n",
    "#c = softmax(c)\n",
    "#print(c)\n",
    "#c = crossEntropy(c,[0,1,0,0])\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5112ce4",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0c940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0b5a30",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b150e4f3",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c0e6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Parametri Architettura ---\n",
    "num_classes = 10\n",
    "bs = 1 # Batch size (mantenuto a 1 come nell'esempio)\n",
    "input_channels = 1 # Scala di grigi\n",
    "kh, kw = 3, 3      # Dimensione Kernel (Height, Width)\n",
    "s = 2              # Stride per tutte le convoluzioni\n",
    "p = 1              # Padding per tutte le convoluzioni (per cercare di mantenere le dimensioni dimezzate)\n",
    "\n",
    "# Layer 1\n",
    "kc1 = 32           # Numero kernel/canali output Layer 1\n",
    "# Layer 2\n",
    "kc2 = 64           # Numero kernel/canali output Layer 2\n",
    "# Layer 3\n",
    "kc3 = 128          # Numero kernel/canali output Layer 3\n",
    "\n",
    "# Calcolo dimensioni output convoluzioni (per FC layer)\n",
    "# Input: 28x28\n",
    "h_in, w_in = 28, 28\n",
    "h_out1 = int(((h_in - kh + 2 * p) / s) + 1) # (28-3+2)/2 + 1 = 14\n",
    "w_out1 = int(((w_in - kw + 2 * p) / s) + 1) # (28-3+2)/2 + 1 = 14\n",
    "h_out2 = int(((h_out1 - kh + 2 * p) / s) + 1) # (14-3+2)/2 + 1 = 7\n",
    "w_out2 = int(((w_out1 - kw + 2 * p) / s) + 1) # (14-3+2)/2 + 1 = 7\n",
    "h_out3 = int(((h_out2 - kh + 2 * p) / s) + 1) # (7-3+2)/2 + 1 = 4\n",
    "w_out3 = int(((w_out2 - kw + 2 * p) / s) + 1) # (7-3+2)/2 + 1 = 4\n",
    "\n",
    "# Dimensione input per FC layer\n",
    "fc_input_size = kc3 * h_out3 * w_out3 # 128 * 4 * 4 = 2048\n",
    "fc_hidden_size = 250 # Dimensione layer nascosto FC\n",
    "\n",
    "# --- Inizializzazione Pesi ---\n",
    "# Kernel Convoluzionali (Formato: InputChannels, OutputChannels, KernelHeight, KernelWidth)\n",
    "# -> NOTA: Adatto il formato a (in_channels, out_channels, kh, kw) che è più standard\n",
    "#         Se le tue funzioni USANO (in_channels, kw, kh, out_channels) come nel codice\n",
    "#         originale, DEVI aggiustare l'ordine qui sotto E nelle funzioni!\n",
    "#         Assumiamo ora (in_channels, out_channels, kh, kw)\n",
    "\n",
    "# k1: 1 -> 32 channels, kernel 3x3\n",
    "k1 = np.random.randn(input_channels, kc1, kh, kw) * 0.01\n",
    "# k2: 32 -> 64 channels, kernel 3x3\n",
    "k2 = np.random.randn(kc1, kc2, kh, kw) * 0.01\n",
    "# k3: 64 -> 128 channels, kernel 3x3\n",
    "k3 = np.random.randn(kc2, kc3, kh, kw) * 0.01\n",
    "\n",
    "# Pesi Fully Connected\n",
    "# w1: Da output conv flattenato (2048) a hidden layer (250)\n",
    "w1 = np.random.randn(fc_input_size, fc_hidden_size) * 0.01\n",
    "b1 = np.zeros((1, fc_hidden_size))\n",
    "# w2: Da hidden layer (250) a output classes (10)\n",
    "w2 = np.random.randn(fc_hidden_size, num_classes) * 0.01\n",
    "b2 = np.zeros((1, num_classes))\n",
    "\n",
    "# --- Parametri Training ---\n",
    "length = images.shape[0] # Numero totale di immagini\n",
    "lr = 0.001               # Learning rate (ridotto rispetto all'originale)\n",
    "num_epochs = 3           # Aumentato per vedere qualche cambiamento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a729d70",
   "metadata": {},
   "source": [
    "#### Cicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   1%|          | 682/60000 [35:44<51:48:39,  3.14s/it, loss=2.3018]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 97\u001b[39m\n\u001b[32m     94\u001b[39m     k3 -= lr * d_k3\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# Aggiorna la barra di progresso con la loss media finora\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     loop.set_postfix(loss=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_loss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# Fine Epoch\u001b[39;00m\n\u001b[32m    100\u001b[39m end_time = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\roman.LAPTOP-AP4SF555\\anaconda3\\envs\\IndustrialApplications\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3380\u001b[39m, in \u001b[36m_mean_dispatcher\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3365\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3366\u001b[39m \u001b[33;03m    Round an array to the given number of decimals.\u001b[39;00m\n\u001b[32m   3367\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3375\u001b[39m \n\u001b[32m   3376\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   3377\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[33m'\u001b[39m\u001b[33mround\u001b[39m\u001b[33m'\u001b[39m, decimals=decimals, out=out)\n\u001b[32m-> \u001b[39m\u001b[32m3380\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mean_dispatcher\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mNone\u001b[39;00m, *,\n\u001b[32m   3381\u001b[39m                      where=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   3382\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, where, out)\n\u001b[32m   3385\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_mean_dispatcher)\n\u001b[32m   3386\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmean\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, *,\n\u001b[32m   3387\u001b[39m          where=np._NoValue):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- Ciclo di Training ---\n",
    "print(\"Inizio Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    start_time = time.time()\n",
    "    # Usiamo tqdm per la barra di progresso sull'intero dataset per epoca\n",
    "    loop = tqdm(range(0, length, bs), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for i in loop:\n",
    "        # --- Mini-batch ---\n",
    "        images_batch = images[i:(i+bs)] # Shape (bs, 1, 28, 28)\n",
    "        labels_batch = labels[i:(i+bs)] # Shape (bs, 10) - One-hot\n",
    "        images_batch = images_batch.reshape(1,1,28,28)\n",
    "        # --- Forward Pass ---\n",
    "        # Layer 1: Conv + ReLU\n",
    "        # Input: (bs, 1, 28, 28), k1: (1, 32, 3, 3) -> Output: (bs, 32, 14, 14)\n",
    "        rs1 = ReLU_ConvolutionS(images_batch, k1, p=p, s=s)\n",
    "\n",
    "        # Layer 2: Conv + ReLU\n",
    "        # Input: (bs, 32, 14, 14), k2: (32, 64, 3, 3) -> Output: (bs, 64, 7, 7)\n",
    "        rs2 = ReLU_ConvolutionS(rs1, k2, p=p, s=s)\n",
    "\n",
    "        # Layer 3: Conv + ReLU\n",
    "        # Input: (bs, 64, 7, 7), k3: (64, 128, 3, 3) -> Output: (bs, 128, 4, 4)\n",
    "        rs3 = ReLU_ConvolutionS(rs2, k3, p=p, s=s)\n",
    "\n",
    "        # Flatten l'output dell'ultimo layer convoluzionale\n",
    "        # Input: (bs, 128, 4, 4) -> Output: (bs, 2048)\n",
    "        i_mlp = rs3.reshape(bs, -1)\n",
    "\n",
    "        # Layer 4 & 5: Fully Connected + ReLU -> Fully Connected + Softmax\n",
    "        fl, fa, sl, pred = ReLU_SoftMax_FullyConnected(i_mlp, w1, b1, w2, b2)\n",
    "\n",
    "        # --- Loss ---\n",
    "        loss = crossEntropy(pred, labels_batch)\n",
    "        epoch_loss.append(loss)\n",
    "\n",
    "        # --- Backward Pass ---\n",
    "        # Backprop attraverso Softmax + CrossEntropy (semplificato)\n",
    "        # dL/dsl = pred - labels_batch (gradiente dell'output prima di Softmax)\n",
    "        dL_dsl = pred - labels_batch # Shape (bs, 10)\n",
    "\n",
    "        # Backprop attraverso FC2 (Layer 5)\n",
    "        # dL/dw2 = dL/dsl * dsl/dw2 = fa.T @ dL_dsl\n",
    "        dL_dw2 = fa.T @ dL_dsl # Shape (250, 10)\n",
    "        # dL/db2 = sum(dL/dsl)\n",
    "        dL_db2 = np.sum(dL_dsl, axis=0, keepdims=True) # Shape (1, 10)\n",
    "        # dL/dfa = dL/dsl * dsl/dfa = dL_dsl @ w2.T\n",
    "        dL_dfa = dL_dsl @ w2.T # Shape (bs, 250)\n",
    "\n",
    "        # Backprop attraverso ReLU (Layer 4)\n",
    "        # dL/dfl = dL/dfa * dfa/dfl\n",
    "        dReLU = (fl > 0).astype(float) # Gradiente ReLU\n",
    "        dL_dfl = dL_dfa * dReLU # Shape (bs, 250)\n",
    "\n",
    "        # Backprop attraverso FC1 (Layer 4)\n",
    "        # dL/dw1 = dL/dfl * dfl/dw1 = i_mlp.T @ dL_dfl\n",
    "        dL_dw1 = i_mlp.T @ dL_dfl # Shape (2048, 250)\n",
    "        # dL/db1 = sum(dL/dfl)\n",
    "        dL_db1 = np.sum(dL_dfl, axis=0, keepdims=True) # Shape (1, 250)\n",
    "        # dL/di_mlp = dL/dfl * dfl/di_mlp = dL_dfl @ w1.T\n",
    "        dL_di_mlp = dL_dfl @ w1.T # Shape (bs, 2048)\n",
    "\n",
    "        # Backprop attraverso Flatten (Layer 3 output)\n",
    "        # Reshape del gradiente per matchare l'output del conv layer 3\n",
    "        # Input grad: (bs, 2048) -> Output grad: (bs, 128, 4, 4)\n",
    "        d_rs3 = dL_di_mlp.reshape(rs3.shape)\n",
    "\n",
    "        # Backprop attraverso Conv3 (Layer 3)\n",
    "        # Input grad: d_rs3 (bs, 128, 4, 4)\n",
    "        # Restituisce d_rs2 (grad per l'input rs2) e d_k3 (grad per kernel k3)\n",
    "        d_rs2, d_k3 = ReLU_ConvolutionS_backward(d_rs3, rs2, k3, rs3, p=p, s=s)\n",
    "        # d_rs2 shape: (bs, 64, 7, 7), d_k3 shape: (64, 128, 3, 3)\n",
    "\n",
    "        # Backprop attraverso Conv2 (Layer 2)\n",
    "        # Input grad: d_rs2 (bs, 64, 7, 7)\n",
    "        # Restituisce d_rs1 (grad per l'input rs1) e d_k2 (grad per kernel k2)\n",
    "        d_rs1, d_k2 = ReLU_ConvolutionS_backward(d_rs2, rs1, k2, rs2, p=p, s=s)\n",
    "        # d_rs1 shape: (bs, 32, 14, 14), d_k2 shape: (32, 64, 3, 3)\n",
    "\n",
    "        # Backprop attraverso Conv1 (Layer 1)\n",
    "        # Input grad: d_rs1 (bs, 32, 14, 14)\n",
    "        # Restituisce d_boi (non usato qui) e d_k1 (grad per kernel k1)\n",
    "        _, d_k1 = ReLU_ConvolutionS_backward(d_rs1, images_batch, k1, rs1, p=p, s=s)\n",
    "        # d_k1 shape: (1, 32, 3, 3)\n",
    "\n",
    "        # --- Aggiornamento Pesi ---\n",
    "        w1 -= lr * dL_dw1\n",
    "        b1 -= lr * dL_db1\n",
    "        w2 -= lr * dL_dw2\n",
    "        b2 -= lr * dL_db2\n",
    "        k1 -= lr * d_k1\n",
    "        k2 -= lr * d_k2\n",
    "        k3 -= lr * d_k3\n",
    "\n",
    "        # Aggiorna la barra di progresso con la loss media finora\n",
    "        loop.set_postfix(loss=f\"{np.mean(epoch_loss):.4f}\")\n",
    "\n",
    "    # Fine Epoch\n",
    "    end_time = time.time()\n",
    "    avg_epoch_loss = np.mean(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1} completata in {end_time - start_time:.2f}s - Loss Media: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training Completato.\")\n",
    "np.savez(\"CNNSlow_w1b1w2b2k1k2k3.npz\",w1,b1,w2,b2,k1,k2,k3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89332ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arr_0', 'arr_1', 'arr_2', 'arr_3', 'arr_4', 'arr_5', 'arr_6')\n"
     ]
    }
   ],
   "source": [
    "np.savez(\"CNNSlow_w1b1w2b2k1k2k3.npz\",w1,b1,w2,b2,k1,k2,k3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdfa23",
   "metadata": {},
   "source": [
    "## CNN - Fast Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16160fe3",
   "metadata": {},
   "source": [
    "### Layers description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8946b2c",
   "metadata": {},
   "source": [
    "#### Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9662d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "k\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "X_c\n",
      "[[14. 22.]\n",
      " [46. 54.]]\n",
      "This is the backward of the ReLU Convolution\n",
      "dX,X,kernel shapes\n",
      "(1, 4)\n",
      "(9, 4)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "def ReLU_Convolution(batch_of_images,kernel,p=0,s=1):\n",
    "    if len(kernel.shape)==2:\n",
    "        kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        nc = 1\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "    else:\n",
    "        ac, kc, kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        #p = 0 # padding\n",
    "        #s = 1 # stride\n",
    "        # im2col: Window creation\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "    # Convolution\n",
    "    kernel = kernel.reshape((kw*kh*nc),-1)\n",
    "    c_m = window_m @ kernel # convolved image matrix\n",
    "    # ReLU activation\n",
    "    r_c_m = np.maximum(0,c_m) # convolved image matrix after ReLU activation\n",
    "    \n",
    "    niw = round(((iw-kw+(2*p))/s)+1) # new image width\n",
    "    nih = round(((ih-kh+(2*p))/s)+1) # new image height\n",
    "    \n",
    "    # First operate a reshape keeping spatial ordering, which has channels at the end\n",
    "    if len(kernel.shape)==2:\n",
    "        reshaped_correct_order = r_c_m.reshape(nih, niw)\n",
    "    else:\n",
    "        output_temp = r_c_m.reshape(bs, nih, niw, kc)\n",
    "        # Transpose to have input in shapes (batch, canali_output, height, width)\n",
    "        reshaped_correct_order = output_temp.transpose(0, 3, 1, 2)\n",
    "    return reshaped_correct_order\n",
    "\n",
    "\n",
    "def ReLU_Convolution_Backward(batch_of_images,kernel,dX,p=0,s=1):\n",
    "    print(\"This is the backward of the ReLU Convolution\")\n",
    "    if len(kernel.shape)==2:\n",
    "        kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        nc = 1\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "        window_m_dx = np.lib.stride_tricks.sliding_window_view(dX,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix of dX\n",
    "    else:\n",
    "        ac, kc, kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        #p = 0 # padding\n",
    "        #s = 1 # stride\n",
    "        # im2col: Window creation\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "        window_m_dx = np.lib.stride_tricks.sliding_window_view(dX,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix of dX\n",
    "    # Convolution\n",
    "    kernel = kernel.reshape((kw*kh*nc),-1)\n",
    "    c_m = window_m @ kernel # convolved image matrix\n",
    "    # ReLU activation\n",
    "    r_c_m = np.maximum(0,c_m) # convolved image matrix after ReLU activation\n",
    "    r_c_m[r_c_m>0]=1 # Backward ReLU\n",
    "    print(\"dX,X,kernel shapes\")\n",
    "    print(window_m_dx.shape)\n",
    "    print(window_m.shape)\n",
    "    print(kernel.shape)\n",
    "\n",
    "\n",
    "X=np.arange(1,4*4+1).reshape(4,4)\n",
    "k = np.ones(1*2*2).reshape(2,2)\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"k\")\n",
    "print(k)\n",
    "X_c = ReLU_Convolution(X,k,s=2)\n",
    "print(\"X_c\")\n",
    "print(X_c)\n",
    "ReLU_Convolution_Backward(X,k,X_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76201de3",
   "metadata": {},
   "source": [
    "#### Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPooling(boi, winSize=2, stride=2):\n",
    "    bs, nc, H_in, W_in = boi.shape\n",
    "\n",
    "    H_out = math.floor((H_in - winSize) / stride) + 1\n",
    "    W_out = math.floor((W_in - winSize) / stride) + 1\n",
    "\n",
    "    output_window_shape = (bs, nc, H_out, W_out, winSize, winSize)\n",
    "    \n",
    "    y_windows = np.lib.stride_tricks.as_strided(boi, shape=output_window_shape)\n",
    "\n",
    "    reshaped_y_for_max = y_windows.reshape(bs * nc * H_out * W_out, winSize * winSize)\n",
    "    \n",
    "    indices = np.argmax(reshaped_y_for_max, axis=1) # Indici piatti (0 a winSize*winSize-1)\n",
    "    max_values = reshaped_y_for_max.max(axis=1)\n",
    "    \n",
    "    pooled_output = max_values.reshape(bs, nc, H_out, W_out)\n",
    "    \n",
    "    cache = (boi.shape, indices, winSize, stride) # indices è 1D\n",
    "    return pooled_output, cache\n",
    "\n",
    "def BackwardMaxPooling(d_out, cache):\n",
    "\n",
    "    A_prev_shape, indices_flat, winSize, stride = cache\n",
    "    bs, nc, H_prev, W_prev = A_prev_shape\n",
    "    _, _, H_out, W_out = d_out.shape\n",
    "\n",
    "    dA_prev = np.zeros(A_prev_shape)\n",
    "\n",
    "    idx_row_in_window = indices_flat // winSize\n",
    "    idx_col_in_window = indices_flat % winSize  \n",
    "\n",
    "\n",
    "    b_idx, ch_idx, r_out_idx, c_out_idx = np.indices((bs, nc, H_out, W_out))\n",
    "\n",
    "    vert_start = r_out_idx * stride \n",
    "    horiz_start = c_out_idx * stride \n",
    "\n",
    "    idx_row_in_window_reshaped = idx_row_in_window.reshape(bs, nc, H_out, W_out)\n",
    "    idx_col_in_window_reshaped = idx_col_in_window.reshape(bs, nc, H_out, W_out)\n",
    "    \n",
    "    abs_row_coords = vert_start + idx_row_in_window_reshaped \n",
    "    abs_col_coords = horiz_start + idx_col_in_window_reshaped \n",
    "    \n",
    "    indices_for_add_at = (\n",
    "        b_idx,                  \n",
    "        ch_idx,                 \n",
    "        abs_row_coords,         \n",
    "        abs_col_coords        \n",
    "    )\n",
    "    \n",
    "    np.add.at(dA_prev, indices_for_add_at, d_out)\n",
    "    \n",
    "    return dA_prev\n",
    "\n",
    "#X = np.arange(1,33).reshape(2,1,4,4)\n",
    "#X[0,0,0,0]=100\n",
    "#\n",
    "#pooled,cache = MaxPooling2D(X)\n",
    "#print(cache)\n",
    "#dX = np.array([1,5,2,9,4,3,2,8]).reshape(2,1,2,2)\n",
    "#new_X = backward_maxpool_vectorized(dX,cache)\n",
    "#print(new_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58b263",
   "metadata": {},
   "source": [
    "#### MLP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,axis=-1,keepdims=True))  # for numerical stability\n",
    "    return e_x / np.sum(e_x,axis=-1,keepdims=True)\n",
    "\n",
    "def ReLU_SoftMax_FullyConnected(input_array,w1,b1,w2,b2):\n",
    "    fl = (input_array @ w1)+b1 # first layer\n",
    "    fa = np.maximum(0,fl) # first activation: ReLU\n",
    "    sl = (fa @ w2)+b2 # second layer\n",
    "    sa = softmax(sl) # second activation: SoftMax\n",
    "    return fl,fa,sl,sa\n",
    "\n",
    "#print(softmax([1,2,3,100000]))\n",
    "#print(softmax_no_NS([1,2,3,1000]))\n",
    "#r = np.array(np.array([1,2,777,2]))\n",
    "#print(softmax(r))\n",
    "#r = np.array((np.array([1,2,777,2]),np.array([1,2,777,2]),np.array([1,2,777,2])))\n",
    "#print(softmax(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92146a63",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    "For this classification problem, the best loss function is the cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(p,t):\n",
    "    # p stands for prediction and t stands for true label\n",
    "    # p = [0,0,1] and t = [1,0,0]\n",
    "    p = p+(1/100000) # for numerical stability\n",
    "    return -np.dot(t,np.log(p).T)\n",
    "\n",
    "#c = [1,1000000000000000,1,1]\n",
    "#c = softmax(c)\n",
    "#print(c)\n",
    "#c = crossEntropy(c,[0,1,0,0])\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe07056",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9223383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k1': array([[[[ 0.25444922, -0.30893782, -0.15066256],\n",
      "         [ 0.0795004 , -0.17761572, -0.22886144],\n",
      "         [ 0.37606657, -0.15557797,  0.08715349]],\n",
      "\n",
      "        [[-0.07796349, -0.1744645 ,  0.32142672],\n",
      "         [ 0.06785692, -0.16283797, -0.14963722],\n",
      "         [-0.22427133, -0.17791815,  0.39172918]],\n",
      "\n",
      "        [[-0.37847936, -0.35440397,  0.19926855],\n",
      "         [-0.46100956,  0.23623335,  0.07524733],\n",
      "         [ 0.00875574,  0.44175863,  0.11696613]],\n",
      "\n",
      "        [[ 0.12216508,  0.04435208,  0.0567803 ],\n",
      "         [-0.0141854 ,  0.22433724,  0.21419233],\n",
      "         [ 0.17017817,  0.02683515, -0.41551712]],\n",
      "\n",
      "        [[-0.04691067, -0.3580202 ,  0.19769657],\n",
      "         [ 0.21854089, -0.08835822,  0.14769632],\n",
      "         [-0.19616129,  0.0176739 ,  0.13939613]],\n",
      "\n",
      "        [[-0.2733364 , -0.35128504, -0.25045168],\n",
      "         [ 0.2601626 ,  0.06937825, -0.41099164],\n",
      "         [ 0.36583582,  0.35990372, -0.12154322]],\n",
      "\n",
      "        [[ 0.16774106,  0.07883533,  0.06790711],\n",
      "         [-0.05339774,  0.00086749, -0.0513436 ],\n",
      "         [-0.03202781, -0.05826066,  0.05629574]],\n",
      "\n",
      "        [[ 0.20253372,  0.01081019, -0.24114877],\n",
      "         [-0.0896482 ,  0.29836112,  0.31837   ],\n",
      "         [-0.45149794,  0.17646497, -0.15014736]],\n",
      "\n",
      "        [[-0.07546975, -0.19350088,  0.09860177],\n",
      "         [ 0.09431664, -0.24391688, -0.02530024],\n",
      "         [-0.06619554, -0.07728831, -0.20340966]],\n",
      "\n",
      "        [[ 0.21053588,  0.38276985, -0.42644748],\n",
      "         [-0.2735879 ,  0.38988864, -0.33050996],\n",
      "         [-0.0018685 ,  0.01846789, -0.02830513]],\n",
      "\n",
      "        [[ 0.06100092, -0.04757801, -0.28852358],\n",
      "         [ 0.24310738, -0.17316216, -0.41470346],\n",
      "         [ 0.5350311 , -0.00909125, -0.0604375 ]],\n",
      "\n",
      "        [[ 0.03651207,  0.08486407,  0.03487795],\n",
      "         [ 0.2793964 , -0.2419324 ,  0.23533385],\n",
      "         [ 0.06388817, -0.01358254,  0.15169886]],\n",
      "\n",
      "        [[ 0.23555651, -0.1424176 , -0.19377737],\n",
      "         [-0.04171665, -0.35376635,  0.255139  ],\n",
      "         [-0.22523354,  0.24479382,  0.16971447]],\n",
      "\n",
      "        [[-0.14188522, -0.23149852, -0.3150246 ],\n",
      "         [-0.26848537, -0.22024582, -0.08666632],\n",
      "         [ 0.11661948,  0.17804843, -0.34537897]],\n",
      "\n",
      "        [[-0.23952045,  0.33316174,  0.07532353],\n",
      "         [ 0.22796915, -0.08337723,  0.2936937 ],\n",
      "         [-0.39911306,  0.18159832, -0.17684518]],\n",
      "\n",
      "        [[ 0.17006458,  0.28008077,  0.40758893],\n",
      "         [-0.25562206, -0.06921346, -0.03514374],\n",
      "         [-0.26988658, -0.20624886, -0.13383362]],\n",
      "\n",
      "        [[-0.12278794,  0.2805377 , -0.33151582],\n",
      "         [-0.03393339,  0.06993686, -0.22448783],\n",
      "         [ 0.1506491 , -0.18405518,  0.33948222]],\n",
      "\n",
      "        [[ 0.1451744 , -0.036187  , -0.32539412],\n",
      "         [ 0.3662245 , -0.20816295, -0.39681715],\n",
      "         [-0.20965719, -0.4432767 ,  0.34822717]],\n",
      "\n",
      "        [[-0.20269832, -0.2849787 ,  0.38338944],\n",
      "         [ 0.317906  , -0.30344963, -0.1257771 ],\n",
      "         [ 0.13861795, -0.40867433,  0.16763617]],\n",
      "\n",
      "        [[-0.14593865,  0.25047645, -0.1408529 ],\n",
      "         [ 0.37361583,  0.41220826, -0.2734612 ],\n",
      "         [ 0.10348565,  0.3102867 , -0.33756605]],\n",
      "\n",
      "        [[ 0.15275705, -0.15880619, -0.28360853],\n",
      "         [-0.36915356, -0.28844532, -0.13231124],\n",
      "         [-0.02011767,  0.11105085,  0.39399678]],\n",
      "\n",
      "        [[-0.15266551,  0.01027918,  0.17077494],\n",
      "         [-0.09808744, -0.37327605,  0.25190902],\n",
      "         [ 0.09131426, -0.24931265,  0.17624198]],\n",
      "\n",
      "        [[-0.28927612,  0.2348068 ,  0.25015688],\n",
      "         [-0.37980217,  0.3072373 ,  0.20810057],\n",
      "         [-0.23051016, -0.35690776,  0.29554516]],\n",
      "\n",
      "        [[ 0.41607425,  0.3883877 ,  0.12873268],\n",
      "         [-0.21242693, -0.17888156, -0.37548545],\n",
      "         [ 0.24284278, -0.25244102, -0.2727316 ]],\n",
      "\n",
      "        [[ 0.10199798, -0.09393535, -0.01168471],\n",
      "         [ 0.3754901 ,  0.22792973, -0.3100591 ],\n",
      "         [-0.2248386 ,  0.2694791 , -0.34262583]],\n",
      "\n",
      "        [[-0.20989576,  0.0141703 ,  0.21564084],\n",
      "         [-0.00587089, -0.23728728,  0.21675344],\n",
      "         [ 0.26785675,  0.19376916, -0.09200617]],\n",
      "\n",
      "        [[-0.24423395, -0.30435556, -0.3787248 ],\n",
      "         [ 0.265502  ,  0.3801462 ,  0.33940062],\n",
      "         [-0.00699675, -0.13425432,  0.1885703 ]],\n",
      "\n",
      "        [[-0.37117234, -0.12709124, -0.07684098],\n",
      "         [ 0.09562939, -0.0558686 , -0.2595587 ],\n",
      "         [-0.19928211, -0.2739441 , -0.27387446]],\n",
      "\n",
      "        [[-0.14024562, -0.39496815,  0.20236962],\n",
      "         [ 0.390882  , -0.26657376, -0.3183154 ],\n",
      "         [-0.01120983,  0.30622637, -0.20808452]],\n",
      "\n",
      "        [[-0.3101789 ,  0.00741742,  0.19680573],\n",
      "         [ 0.10922427,  0.14314769, -0.22518288],\n",
      "         [-0.2798396 ,  0.29845023,  0.12457859]],\n",
      "\n",
      "        [[ 0.04207378,  0.2796863 ,  0.0498092 ],\n",
      "         [ 0.08454975,  0.21733984,  0.2770079 ],\n",
      "         [ 0.03089642,  0.0982586 ,  0.17246711]],\n",
      "\n",
      "        [[-0.31486872, -0.05105469, -0.28256246],\n",
      "         [-0.19917265, -0.39754573,  0.22941965],\n",
      "         [ 0.1377704 ,  0.2870912 , -0.02194192]]]], dtype=float32), 'b_conv1': array([ 0.23229656,  0.03607284, -0.07416921, -0.09402616,  0.00726484,\n",
      "       -0.0979597 ,  0.0842629 , -0.12139785, -0.01675177, -0.02096518,\n",
      "       -0.02385015, -0.4311416 , -0.00543571, -0.12271599,  0.08644359,\n",
      "        0.13608539, -0.07289033, -0.09009103,  0.19915809, -0.09762045,\n",
      "        0.07585163,  0.17117687,  0.05457509, -0.21028253,  0.05808843,\n",
      "       -0.37655902, -0.01237474, -0.35767618,  0.04088894,  0.03838197,\n",
      "        0.09838137, -0.14011057], dtype=float32), 'k2': array([[[[-7.96035752e-02, -5.33823781e-02, -6.96700811e-02],\n",
      "         [ 6.39934763e-02,  3.35746892e-02, -6.33898824e-02],\n",
      "         [ 9.32253972e-02, -3.07081454e-02, -9.98096168e-02]],\n",
      "\n",
      "        [[-3.63237225e-02, -4.81967255e-02,  1.88614711e-01],\n",
      "         [ 5.78934215e-02, -1.13926321e-01,  1.15655661e-01],\n",
      "         [ 3.54085304e-02, -8.06993768e-02,  8.19641054e-02]],\n",
      "\n",
      "        [[ 5.85647076e-02,  2.32414026e-02,  2.34290604e-02],\n",
      "         [ 1.12470500e-02, -1.18301943e-01, -1.34643791e-02],\n",
      "         [-1.24613252e-02, -1.98545400e-02, -3.57175656e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.53335030e-02, -1.70332208e-01,  2.60965079e-02],\n",
      "         [-5.47740497e-02, -1.48049332e-02,  4.40062061e-02],\n",
      "         [-2.03454755e-02,  1.71608869e-02,  1.98882204e-02]],\n",
      "\n",
      "        [[-3.21117230e-02,  1.19438104e-01,  7.91548565e-03],\n",
      "         [-9.36501175e-02,  3.23939249e-02,  3.94356698e-02],\n",
      "         [-5.17187789e-02,  5.01634181e-02,  1.09642912e-02]],\n",
      "\n",
      "        [[ 9.99182612e-02,  3.78065072e-02,  1.85303837e-02],\n",
      "         [-4.67977412e-02,  7.32391626e-02, -3.74920270e-03],\n",
      "         [ 1.23734251e-02, -5.18995058e-03, -1.33999452e-01]]],\n",
      "\n",
      "\n",
      "       [[[-8.91091824e-02,  1.72500145e-02,  6.11666813e-02],\n",
      "         [-9.97582301e-02,  6.16324283e-02, -4.09782678e-03],\n",
      "         [ 2.59981267e-02, -8.23614653e-03,  2.28580600e-03]],\n",
      "\n",
      "        [[ 1.01839080e-01,  3.14166434e-02, -1.40923038e-01],\n",
      "         [ 1.54432252e-01, -5.55771515e-02, -5.17394952e-03],\n",
      "         [ 1.37133092e-01,  9.55977440e-02, -5.75178266e-02]],\n",
      "\n",
      "        [[ 1.57489106e-02, -1.66460546e-03, -3.79755948e-05],\n",
      "         [ 3.13261487e-02,  3.52296121e-02, -2.01028615e-01],\n",
      "         [-4.07686718e-02, -1.65999383e-01,  1.76214818e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 1.08824857e-01, -6.36339411e-02, -8.23815167e-02],\n",
      "         [-4.79292683e-02, -9.49425995e-02, -6.25388101e-02],\n",
      "         [-1.21472940e-01, -4.53488864e-02, -7.62214065e-02]],\n",
      "\n",
      "        [[ 1.02212399e-01, -1.98182374e-01,  9.69814062e-02],\n",
      "         [ 2.88180690e-02, -8.55452046e-02,  1.58599615e-02],\n",
      "         [-1.41070634e-01,  6.73914030e-02,  5.37234955e-02]],\n",
      "\n",
      "        [[-1.55480862e-01,  3.72435525e-02, -3.02476976e-02],\n",
      "         [-1.68145210e-01,  1.53808281e-01, -1.16529301e-01],\n",
      "         [-1.50888428e-01,  1.10084429e-01,  2.65910495e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.23673019e-02, -4.57405373e-02, -7.44066527e-03],\n",
      "         [-3.99407893e-02, -3.45672891e-02,  3.78977731e-02],\n",
      "         [-1.01928204e-01,  1.97454151e-02,  3.85524100e-03]],\n",
      "\n",
      "        [[-4.54591475e-02, -1.32159714e-03, -1.15671962e-01],\n",
      "         [-3.42671610e-02,  9.71404389e-02, -1.60261273e-01],\n",
      "         [ 1.02584049e-01,  9.36886519e-02, -7.37260878e-02]],\n",
      "\n",
      "        [[-1.15235485e-01,  6.55929744e-02,  8.35085139e-02],\n",
      "         [-2.81000440e-03,  1.27343372e-01, -1.34419193e-02],\n",
      "         [ 1.97615530e-02, -5.83100505e-02, -1.94012895e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 8.95519853e-02,  1.47486880e-01, -5.40338978e-02],\n",
      "         [ 9.35506076e-02,  3.60591374e-02,  1.80437248e-02],\n",
      "         [-6.39858991e-02, -9.89943966e-02, -1.23639598e-01]],\n",
      "\n",
      "        [[ 8.70630890e-02, -1.48903817e-01, -8.36863741e-02],\n",
      "         [ 2.41322786e-01, -4.89300750e-02, -5.70694283e-02],\n",
      "         [ 1.59125075e-01, -2.88413376e-01,  1.65491313e-01]],\n",
      "\n",
      "        [[ 1.09411240e-01, -2.78766096e-01, -1.31794589e-03],\n",
      "         [ 4.05796580e-02, -1.52147368e-01,  1.62264407e-01],\n",
      "         [-1.14022262e-01, -3.95786911e-02,  3.33557576e-02]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[-5.09652048e-02, -5.60988523e-02,  8.64249691e-02],\n",
      "         [-1.87325552e-02, -5.07017933e-02,  8.17477405e-02],\n",
      "         [-8.55083689e-02, -6.65731868e-03,  7.51463994e-02]],\n",
      "\n",
      "        [[ 1.81548018e-03,  4.09996435e-02, -7.15837628e-02],\n",
      "         [-4.35881577e-02,  1.59370437e-01, -2.54983101e-02],\n",
      "         [-5.29285222e-02,  1.08988941e-01, -9.93651748e-02]],\n",
      "\n",
      "        [[-5.75385243e-02,  3.10606826e-02, -1.08890459e-02],\n",
      "         [ 3.59644331e-02,  3.17745432e-02,  5.63179217e-02],\n",
      "         [ 1.07424455e-02, -5.42751998e-02, -1.00523591e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.03813380e-02,  7.25077987e-02, -6.08682521e-02],\n",
      "         [ 2.67420784e-02, -8.20922703e-02, -7.68098086e-02],\n",
      "         [-1.13842851e-02, -1.08818188e-01, -4.84440513e-02]],\n",
      "\n",
      "        [[ 4.64412831e-02, -7.02036396e-02, -1.79222561e-02],\n",
      "         [ 7.91048110e-02, -7.90790543e-02, -1.06759742e-01],\n",
      "         [ 2.21487090e-01, -1.62997693e-01, -2.62650084e-02]],\n",
      "\n",
      "        [[ 4.47271243e-02, -1.62925854e-01,  1.16083154e-03],\n",
      "         [ 3.39907929e-02, -5.40420301e-02,  1.59289278e-02],\n",
      "         [ 5.94528904e-03, -1.04681969e-01, -2.33443361e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.41050124e-02, -5.68163544e-02,  7.89679512e-02],\n",
      "         [ 1.57915335e-02, -9.54605266e-02,  7.03788921e-02],\n",
      "         [-5.91819882e-02, -6.73763528e-02,  1.31472349e-01]],\n",
      "\n",
      "        [[-1.39866713e-02,  8.18462819e-02, -7.16709867e-02],\n",
      "         [-8.95936489e-02,  5.55916168e-02,  1.22039821e-02],\n",
      "         [-6.86331466e-02,  1.00293048e-01,  2.45474689e-02]],\n",
      "\n",
      "        [[ 8.23503888e-06, -6.88841641e-02, -2.36989763e-02],\n",
      "         [-2.10104845e-02,  1.17531434e-01,  8.63277912e-02],\n",
      "         [ 5.65538853e-02,  5.31178974e-02, -7.57298246e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.48237255e-02,  6.99780956e-02,  2.46810187e-02],\n",
      "         [-4.89054509e-02, -7.99738914e-02, -8.23627189e-02],\n",
      "         [ 2.91341301e-02, -5.54608181e-03,  4.17795964e-02]],\n",
      "\n",
      "        [[ 4.98235077e-02, -4.15774994e-02, -1.64294854e-01],\n",
      "         [ 1.34834588e-01, -4.75400127e-02, -8.72538090e-02],\n",
      "         [ 1.31060794e-01, -2.12105941e-02, -7.42461085e-02]],\n",
      "\n",
      "        [[ 6.64643645e-02, -1.05322517e-01, -1.06554024e-01],\n",
      "         [ 1.14695974e-01, -6.50969744e-02, -3.22978571e-02],\n",
      "         [ 5.20147346e-02, -1.31519036e-02,  1.77417155e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 3.25542199e-03, -1.09437294e-01, -1.12692110e-01],\n",
      "         [ 4.31668647e-02, -5.44094183e-02, -1.52626768e-01],\n",
      "         [-7.57746771e-03, -1.43216096e-03, -6.08237013e-02]],\n",
      "\n",
      "        [[-1.49693474e-01, -1.02990858e-01, -1.76515132e-01],\n",
      "         [ 2.59833951e-02, -1.86700001e-01, -1.43225670e-01],\n",
      "         [-6.38274401e-02, -1.26894638e-01, -1.99986666e-01]],\n",
      "\n",
      "        [[-1.31567106e-01,  1.13764919e-01,  1.98583379e-01],\n",
      "         [ 1.12207951e-02,  6.68346658e-02,  6.55344576e-02],\n",
      "         [ 8.57438296e-02, -7.93818235e-02, -7.30244294e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.25051884e-02,  1.70297012e-01, -7.98825473e-02],\n",
      "         [ 5.59934862e-02, -3.88501734e-02,  6.94344491e-02],\n",
      "         [-9.50570926e-02, -7.07978234e-02, -6.50122762e-02]],\n",
      "\n",
      "        [[-3.09708361e-02,  1.83724649e-02, -4.24647406e-02],\n",
      "         [ 1.93135664e-02, -2.01551005e-01, -9.38295200e-02],\n",
      "         [-5.49550876e-02, -1.40880749e-01,  1.30892433e-02]],\n",
      "\n",
      "        [[-3.06126513e-02, -6.24339730e-02,  1.10502250e-01],\n",
      "         [-1.52488099e-02, -2.38252059e-03,  1.18589431e-01],\n",
      "         [-1.40063509e-01, -4.09333296e-02, -4.31457311e-02]]]],\n",
      "      dtype=float32), 'b_conv2': array([-3.9524160e-02,  8.0833122e-02, -2.3887780e-02, -2.2026233e-02,\n",
      "        6.1614383e-02,  3.7542485e-02, -6.8075284e-03,  3.3241011e-02,\n",
      "        6.0907472e-03,  3.0309426e-02, -4.1608144e-02,  7.2395490e-03,\n",
      "        1.3290817e-02, -1.0777028e-02, -9.1468869e-03, -5.5397805e-02,\n",
      "       -8.9399321e-03, -6.8050191e-02,  2.3665003e-02, -1.7248605e-03,\n",
      "       -3.1710144e-02,  2.2879919e-02, -6.6261011e-04,  5.7318769e-02,\n",
      "       -3.1053787e-02,  2.4664858e-02, -4.5048486e-02,  3.4582105e-02,\n",
      "        1.3582067e-02,  1.6240190e-03,  4.6489902e-02, -8.3582072e-06,\n",
      "       -5.0901704e-02,  1.4334814e-02,  1.6418815e-02,  6.6734850e-02,\n",
      "       -3.0579738e-02,  3.4867488e-02,  4.3400016e-02,  3.7237078e-02,\n",
      "        1.9743569e-02, -4.4961583e-02, -7.6847672e-02,  4.1882459e-02,\n",
      "        2.1998452e-02,  9.5794886e-02, -3.6753215e-02,  4.6472311e-02,\n",
      "        1.7480478e-02,  6.5351869e-03,  1.4350611e-02,  1.6661067e-02,\n",
      "        5.2880313e-02, -2.4158746e-02, -1.8263161e-02,  7.2196350e-02,\n",
      "       -2.9322959e-02, -4.5360316e-02,  2.9702766e-02, -6.2292289e-02,\n",
      "       -7.5038947e-02, -5.6018952e-02, -2.0798093e-02,  2.9321665e-02],\n",
      "      dtype=float32), 'k3': array([[[[-6.74339086e-02, -1.24043226e-01,  2.56092083e-02],\n",
      "         [-1.02697439e-01, -1.39817521e-01, -4.30181064e-02],\n",
      "         [-2.33457983e-02,  6.29364094e-03,  1.14310691e-02]],\n",
      "\n",
      "        [[ 3.25714722e-02,  2.94954889e-02, -4.23334576e-02],\n",
      "         [-5.55645600e-02,  2.19061598e-03, -1.34466216e-01],\n",
      "         [ 3.91385518e-02,  4.91360016e-02, -8.72863233e-02]],\n",
      "\n",
      "        [[-8.16837177e-02,  8.19103494e-02, -6.20220322e-03],\n",
      "         [-1.50953501e-01,  4.47796620e-02, -1.51598871e-01],\n",
      "         [-3.72386016e-02,  3.17527801e-02,  2.22495794e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.61169299e-02,  1.23634011e-01, -6.92998990e-02],\n",
      "         [ 9.68525279e-03, -1.41254375e-02, -1.55543730e-01],\n",
      "         [ 6.57277703e-02, -1.23882331e-02, -2.11309865e-02]],\n",
      "\n",
      "        [[ 1.06196240e-01, -1.25700474e-01, -2.36694999e-02],\n",
      "         [ 4.59125638e-02, -4.93250452e-02, -3.61097278e-03],\n",
      "         [ 1.43563319e-02, -8.38335752e-02, -7.50282332e-02]],\n",
      "\n",
      "        [[-6.75338961e-04, -6.67605400e-02, -2.62071639e-02],\n",
      "         [-1.55444592e-02, -4.35068347e-02,  5.73203191e-02],\n",
      "         [-5.57735004e-02,  4.48091328e-02,  1.50986826e-02]]],\n",
      "\n",
      "\n",
      "       [[[-9.53908712e-02, -1.40115023e-01,  4.40701582e-02],\n",
      "         [-1.46617904e-01, -2.18096767e-02, -3.53453830e-02],\n",
      "         [-1.19188964e-01, -1.60002727e-02,  2.78604180e-02]],\n",
      "\n",
      "        [[-5.04695140e-02,  2.42711511e-02, -4.82340567e-02],\n",
      "         [ 1.32843864e-03, -9.94217768e-03, -4.24318202e-02],\n",
      "         [-1.18345328e-01,  2.24293619e-02, -7.23300725e-02]],\n",
      "\n",
      "        [[ 8.31004046e-03, -5.43621369e-02,  1.25873044e-01],\n",
      "         [-1.83197767e-01,  4.32296544e-02, -2.11993903e-02],\n",
      "         [-1.46657199e-01,  1.03452474e-01,  1.81055404e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.79877040e-02,  7.49508813e-02, -5.40047400e-02],\n",
      "         [-1.60715863e-01, -6.04117382e-03, -1.61730736e-01],\n",
      "         [-5.97301163e-02,  5.36063686e-02, -5.71503229e-02]],\n",
      "\n",
      "        [[ 9.07064322e-03,  1.20277986e-01,  3.48160556e-03],\n",
      "         [ 2.01698020e-02, -8.48236233e-02,  5.39306067e-02],\n",
      "         [ 4.34086807e-02, -6.64706230e-02,  6.90980628e-02]],\n",
      "\n",
      "        [[-1.44855333e-02,  2.69888509e-02,  1.04036398e-01],\n",
      "         [-3.18391547e-02,  3.85076441e-02, -9.02387947e-02],\n",
      "         [-1.23740181e-01,  1.70534387e-01, -2.83483360e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 4.00822945e-02, -3.63943949e-02,  1.02042779e-01],\n",
      "         [ 1.70703769e-01,  1.41008757e-02, -2.05470645e-03],\n",
      "         [-4.90788408e-02, -1.54213846e-01, -4.49842289e-02]],\n",
      "\n",
      "        [[-3.97277996e-02,  1.09592475e-01, -1.97102074e-02],\n",
      "         [-2.92549059e-02,  1.99805410e-03,  3.47998515e-02],\n",
      "         [-5.38583808e-02,  1.24129616e-01,  2.07374580e-02]],\n",
      "\n",
      "        [[-5.71867302e-02,  5.92432246e-02, -5.39465360e-02],\n",
      "         [-1.04278542e-01, -2.02225037e-02, -7.23018348e-02],\n",
      "         [ 8.23059306e-02,  5.70694031e-03,  8.03347081e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.39544928e-02,  5.62963448e-02,  7.89810792e-02],\n",
      "         [-2.52228556e-03,  1.09660104e-01,  6.50202855e-02],\n",
      "         [-3.46795842e-02, -6.35454506e-02, -1.68086037e-01]],\n",
      "\n",
      "        [[ 1.11370003e-02, -6.52527362e-02, -6.47942275e-02],\n",
      "         [ 6.70614019e-02, -2.09221893e-04,  1.26782134e-01],\n",
      "         [-1.05099259e-02,  8.04416388e-02, -7.04115704e-02]],\n",
      "\n",
      "        [[ 7.38862976e-02, -5.73094338e-02,  1.71995014e-02],\n",
      "         [-9.71376151e-02, -3.50405425e-02, -5.73225357e-02],\n",
      "         [-3.34874839e-02,  2.51269750e-02, -3.94474417e-02]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[ 3.40314023e-02, -2.02008919e-03, -4.72245067e-02],\n",
      "         [-6.41734153e-02, -7.12388754e-02, -1.64712310e-01],\n",
      "         [-9.10919979e-02, -3.22408676e-02,  1.89117007e-02]],\n",
      "\n",
      "        [[ 1.95351318e-02, -1.97929516e-03, -3.18872072e-02],\n",
      "         [ 4.86525968e-02, -8.11298713e-02, -2.08153948e-02],\n",
      "         [ 5.09835780e-02,  1.60957590e-01, -9.91173834e-03]],\n",
      "\n",
      "        [[ 2.58578025e-02, -1.25466645e-01, -3.30976211e-02],\n",
      "         [ 2.27757338e-02, -7.29642212e-02,  4.58575152e-02],\n",
      "         [ 6.40731072e-03, -9.09876823e-03, -5.71675748e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.05522992e-02, -9.92701389e-04,  1.95345320e-02],\n",
      "         [-9.27407644e-04, -6.54444918e-02,  1.77112054e-02],\n",
      "         [-9.67296027e-03, -2.42258795e-02, -1.41013181e-02]],\n",
      "\n",
      "        [[-7.94095322e-02,  6.87243119e-02, -1.21673904e-01],\n",
      "         [ 7.85785019e-02,  2.67694704e-02,  5.52928410e-02],\n",
      "         [ 3.82943600e-02,  8.50942545e-03, -6.04526047e-03]],\n",
      "\n",
      "        [[ 2.29716464e-03,  1.74373563e-04, -5.54711483e-02],\n",
      "         [-1.22812586e-02, -1.71566904e-02,  5.77700622e-02],\n",
      "         [ 2.31409948e-02, -4.32504108e-03, -9.51272547e-02]]],\n",
      "\n",
      "\n",
      "       [[[-2.76175723e-03, -7.78084397e-02, -4.32916917e-02],\n",
      "         [-1.42656520e-01,  3.73787135e-02, -1.12616129e-01],\n",
      "         [ 9.85952914e-02, -1.64496601e-02, -8.89171809e-02]],\n",
      "\n",
      "        [[ 6.83480054e-02, -1.03196189e-01,  1.31247994e-02],\n",
      "         [ 7.05613568e-02, -1.72481928e-02, -1.98175654e-01],\n",
      "         [-5.19393757e-02, -3.57041694e-02, -8.49572718e-02]],\n",
      "\n",
      "        [[ 3.23260985e-02, -1.62169993e-01, -2.50166636e-02],\n",
      "         [ 1.59127172e-02, -9.67430994e-02,  2.58753374e-02],\n",
      "         [ 2.70768814e-02,  5.00829853e-02, -1.76078547e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-9.19972733e-02,  1.21749282e-01,  3.81655656e-02],\n",
      "         [-2.10718378e-01, -9.19382274e-03, -5.45007177e-02],\n",
      "         [-1.49776936e-01, -3.83455656e-03, -7.04471394e-03]],\n",
      "\n",
      "        [[-3.08885276e-02,  1.05975725e-01, -1.16403766e-01],\n",
      "         [-4.57812920e-02,  7.43717253e-02, -4.89284769e-02],\n",
      "         [-1.60720304e-01, -9.49828550e-02,  4.35131118e-02]],\n",
      "\n",
      "        [[-8.53154734e-02, -5.09931110e-02, -7.88945854e-02],\n",
      "         [ 5.00490777e-02, -5.60479574e-02, -2.01657787e-02],\n",
      "         [ 7.95369670e-02, -2.41035409e-03, -1.29284225e-02]]],\n",
      "\n",
      "\n",
      "       [[[ 6.30000681e-02, -3.20747867e-02, -1.04493305e-01],\n",
      "         [-1.07775312e-02, -2.62017362e-02, -1.96918659e-02],\n",
      "         [ 7.52421394e-02, -3.93465534e-02, -1.03603743e-01]],\n",
      "\n",
      "        [[ 2.48982059e-03, -9.87280011e-02,  6.76450804e-02],\n",
      "         [ 4.62344028e-02,  3.03077828e-02, -3.78481857e-02],\n",
      "         [ 2.40988284e-02, -1.12068571e-01, -4.67699356e-02]],\n",
      "\n",
      "        [[ 1.86079368e-02, -7.48132318e-02, -2.91910861e-02],\n",
      "         [ 6.44448102e-02, -4.71397266e-02,  2.40789237e-03],\n",
      "         [ 1.01666078e-01, -7.33135641e-03, -5.20254187e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-7.45658726e-02,  4.21297066e-02,  8.42017680e-02],\n",
      "         [-8.21498185e-02,  3.30028031e-03, -3.68121155e-02],\n",
      "         [-7.82077834e-02, -6.25575855e-02, -1.33892260e-02]],\n",
      "\n",
      "        [[-4.29206667e-03,  9.07415822e-02, -4.14322689e-02],\n",
      "         [ 2.85428762e-03,  1.18178956e-01, -4.28256243e-02],\n",
      "         [-1.03763618e-01, -4.18994352e-02,  1.07761053e-02]],\n",
      "\n",
      "        [[-1.26443598e-02, -3.05378176e-02, -3.71507406e-02],\n",
      "         [ 1.16382586e-02, -2.25340258e-02, -4.46215868e-02],\n",
      "         [ 9.61310267e-02, -2.93215867e-02,  2.96707451e-02]]]],\n",
      "      dtype=float32), 'b_conv3': array([-4.23619188e-02, -4.59236018e-02,  3.75348851e-02, -2.55851466e-02,\n",
      "       -3.47427614e-02,  4.84083630e-02,  1.64000858e-02, -4.11338285e-02,\n",
      "       -7.90161490e-02, -4.73823957e-02, -1.58257023e-01,  8.70929807e-02,\n",
      "       -3.39466818e-02, -1.01564296e-01,  2.12208088e-02, -4.18040566e-02,\n",
      "       -4.20032721e-03, -1.36237647e-02, -3.03817168e-02, -7.09910784e-03,\n",
      "       -5.38155288e-02, -1.67240798e-02, -1.70444027e-02, -4.25498337e-02,\n",
      "       -1.47404568e-02, -9.25285667e-02, -1.86111722e-02, -1.57319959e-02,\n",
      "       -1.86827574e-02, -3.84316631e-02, -5.53264804e-02, -9.73756835e-02,\n",
      "        9.49065946e-03, -6.65146261e-02, -1.96302738e-02, -5.54149114e-02,\n",
      "       -8.24840367e-02, -3.70778032e-02, -7.61003569e-02, -3.04620378e-02,\n",
      "       -2.82663703e-02, -9.31013823e-02,  1.17481900e-02, -2.14641523e-02,\n",
      "       -1.89498439e-02, -7.84349442e-02,  3.50477360e-02, -5.48539162e-02,\n",
      "       -1.44447759e-02,  3.06873908e-03, -4.31446284e-02, -6.66508451e-02,\n",
      "       -1.72208827e-02, -6.37280643e-02, -2.16500740e-02, -7.11412802e-02,\n",
      "       -2.01187022e-02, -1.09442070e-01, -2.21566167e-02,  6.36258814e-03,\n",
      "       -2.04520468e-02, -9.87962447e-03, -9.70505923e-02, -5.76261021e-02,\n",
      "        1.59752704e-02,  9.07982327e-03, -1.45425806e-02, -3.14358063e-02,\n",
      "        2.08470896e-02, -7.18352422e-02, -8.21538046e-02, -1.15668744e-01,\n",
      "       -6.90311641e-02, -3.41884717e-02, -1.69844572e-02,  6.97344635e-03,\n",
      "       -2.30612271e-02, -4.20839749e-02, -5.76854497e-02,  4.86599542e-02,\n",
      "       -1.10035138e-02, -4.25246134e-02, -3.63618657e-02,  7.48284301e-03,\n",
      "       -3.99817079e-02, -6.51241094e-02, -4.95192446e-02,  7.99995009e-03,\n",
      "        1.52905826e-02,  2.19466500e-02, -3.50895226e-02,  4.18349588e-03,\n",
      "       -8.61781090e-03,  1.82332471e-02, -3.62589657e-02, -7.86413625e-02,\n",
      "        2.17382070e-02, -4.05463576e-02, -9.76957902e-02, -2.29234695e-02,\n",
      "       -1.69386007e-02, -5.32968827e-02, -1.01596698e-01, -1.63942371e-02,\n",
      "       -1.14367402e-03,  2.13364307e-02,  1.11712879e-02, -1.72798559e-02,\n",
      "       -1.21603860e-02, -7.25285634e-02, -5.60248233e-02, -3.27637792e-02,\n",
      "       -8.01851228e-02, -1.25920191e-01, -5.28930314e-02, -9.77140442e-02,\n",
      "       -1.85892768e-02, -2.20947340e-02, -2.45104320e-02, -9.21346769e-02,\n",
      "       -1.36864766e-01,  1.18301567e-02,  5.30483015e-03, -5.80410026e-02,\n",
      "       -1.35215203e-04,  5.83607815e-02, -2.75522452e-02,  8.89445990e-02],\n",
      "      dtype=float32), 'w1': array([[-0.0078881 ,  0.00440972,  0.01892646, ..., -0.01279267,\n",
      "        -0.0055004 , -0.02663296],\n",
      "       [-0.00859418, -0.00795206, -0.02165637, ..., -0.00855807,\n",
      "        -0.02046743, -0.00569573],\n",
      "       [ 0.05443693, -0.05379928, -0.00919662, ...,  0.02997118,\n",
      "        -0.02532608,  0.01025542],\n",
      "       ...,\n",
      "       [-0.04112027, -0.01553032,  0.0243196 , ..., -0.03010551,\n",
      "         0.00068902,  0.01241101],\n",
      "       [-0.00994311,  0.01535401, -0.00420091, ..., -0.01769715,\n",
      "         0.00575155, -0.00324817],\n",
      "       [-0.04351705,  0.00362866, -0.02074636, ..., -0.01852019,\n",
      "        -0.00954069, -0.02547517]], dtype=float32), 'b1': array([[ 0.04373588, -0.00268055,  0.00500064, -0.00067462, -0.02933445,\n",
      "         0.01257114, -0.00844114, -0.01978715, -0.0234607 , -0.01601736,\n",
      "        -0.00780596,  0.00426798,  0.02009823,  0.01817716,  0.0122697 ,\n",
      "         0.02461223, -0.02371949, -0.02954107,  0.02361531, -0.02009849,\n",
      "         0.01619022,  0.00776384,  0.07219294,  0.02583487, -0.02415605,\n",
      "        -0.01630087,  0.00221689,  0.00705713,  0.00959204, -0.01622103,\n",
      "        -0.08387877,  0.03201845,  0.04491019,  0.03503689,  0.02119582,\n",
      "        -0.07361068, -0.02653761,  0.02140411,  0.00277701,  0.0047894 ,\n",
      "         0.0428037 , -0.0294773 ,  0.00200767,  0.04811996, -0.013835  ,\n",
      "         0.00747645, -0.02845083,  0.04593113,  0.01953434,  0.00055198,\n",
      "        -0.05674753,  0.01122697, -0.02146777,  0.00067312, -0.00120668,\n",
      "        -0.01862293,  0.04929443,  0.05840876, -0.05035457, -0.06120731,\n",
      "         0.00620468, -0.02581972, -0.02222342, -0.03614955,  0.03123682,\n",
      "         0.02052688, -0.02915919,  0.01609954, -0.05721288, -0.02856187,\n",
      "        -0.00438738,  0.00286119, -0.06458424, -0.03557112, -0.02621217,\n",
      "        -0.04017358, -0.00899483,  0.01364096, -0.03686418, -0.06211298,\n",
      "         0.05377872, -0.02352379,  0.03511291, -0.02838302, -0.0199312 ,\n",
      "        -0.0454386 ,  0.03418031, -0.00470817, -0.01498898, -0.01417657,\n",
      "        -0.00925595,  0.05344854,  0.03631106,  0.01519957, -0.01257059,\n",
      "        -0.01562256,  0.04766199,  0.0097948 , -0.03345435,  0.01019761,\n",
      "         0.01784317, -0.02181156, -0.03864552,  0.02684435,  0.02877913,\n",
      "        -0.00101172, -0.03334738,  0.08024991, -0.03637628,  0.01005523,\n",
      "        -0.02210611, -0.00769394,  0.00263202,  0.00131862, -0.02432012,\n",
      "        -0.00591278, -0.02429141, -0.01146301,  0.01307028, -0.01395203,\n",
      "         0.00779555, -0.04800193, -0.00171337,  0.02674453, -0.01344479,\n",
      "        -0.01476242,  0.00313114,  0.02949594, -0.01438131,  0.02196434,\n",
      "        -0.0273877 ,  0.0092678 , -0.01017972, -0.04508702, -0.04306725,\n",
      "        -0.00172495, -0.01590578, -0.01759491, -0.0091938 , -0.06019355,\n",
      "         0.02443966,  0.01037981, -0.06354086, -0.00256377, -0.0289249 ,\n",
      "         0.05709497, -0.02657066, -0.01504106, -0.00814714,  0.04984932,\n",
      "        -0.01737152,  0.02716087,  0.03270456, -0.00731643, -0.01126765,\n",
      "         0.00534185,  0.01148047, -0.01426297, -0.00927793, -0.02110377,\n",
      "         0.01711875,  0.00735472, -0.01418472,  0.02131787,  0.01414513,\n",
      "        -0.01243279,  0.03986226,  0.05996802,  0.0308691 ,  0.04052195,\n",
      "        -0.00147685,  0.01535031, -0.00353711, -0.009674  , -0.02755   ,\n",
      "        -0.03891689, -0.0017562 ,  0.00263072,  0.00278076, -0.00532839,\n",
      "        -0.04650969,  0.02701352, -0.00799038, -0.00442127,  0.00974985,\n",
      "        -0.05746183,  0.05486264,  0.0003175 , -0.01765376, -0.03034306,\n",
      "         0.00155321, -0.0135299 , -0.04827274,  0.02319367,  0.00260191,\n",
      "         0.00034225,  0.02359989,  0.01315867, -0.00742858, -0.00529339,\n",
      "        -0.00377928, -0.01786767, -0.01583942, -0.00787884,  0.00303541,\n",
      "        -0.01421113,  0.01405155,  0.02936828, -0.07788312, -0.05850114,\n",
      "        -0.03962901,  0.0105586 , -0.00887834,  0.0301785 ,  0.0520953 ,\n",
      "         0.00537692,  0.0292273 ,  0.06069501,  0.01258991, -0.00935549,\n",
      "        -0.02834568, -0.00485911,  0.02791997, -0.01712001,  0.00808056,\n",
      "         0.00682039,  0.03429968,  0.00473923,  0.05208736,  0.02001038,\n",
      "        -0.01432362, -0.01694932, -0.04328911, -0.04923232, -0.02694204,\n",
      "         0.00467799,  0.02476748, -0.0242681 ,  0.00448206, -0.04565807,\n",
      "        -0.00958907,  0.02592137, -0.03087723, -0.01199304, -0.0051519 ,\n",
      "        -0.0231687 , -0.00547533, -0.00483533,  0.01565708,  0.01024954]],\n",
      "      dtype=float32), 'w2': array([[ 0.03847181,  0.02034864, -0.13537182, ..., -0.00172381,\n",
      "         0.04519251,  0.07983218],\n",
      "       [ 0.06879999, -0.03115371,  0.05056911, ...,  0.05234266,\n",
      "         0.05642221, -0.00713829],\n",
      "       [-0.00940774,  0.05702718, -0.00984929, ...,  0.06833273,\n",
      "         0.00175994, -0.09439155],\n",
      "       ...,\n",
      "       [-0.0543931 ,  0.05594821,  0.06923502, ...,  0.0450103 ,\n",
      "         0.04118857,  0.05570067],\n",
      "       [-0.02522522, -0.01286888, -0.01884684, ..., -0.01413092,\n",
      "        -0.02219444,  0.04954797],\n",
      "       [-0.00144484,  0.04301093,  0.01017024, ..., -0.01985237,\n",
      "        -0.06911294,  0.00791195]], dtype=float32), 'b2': array([[-0.01967418,  0.01349504, -0.05459301, -0.04710745, -0.00091186,\n",
      "         0.02374949, -0.06666202,  0.03304643,  0.05857744, -0.02654943]],\n",
      "      dtype=float32)}\n",
      "(1, 32, 3, 3)\n",
      "(32, 64, 3, 3)\n",
      "(64, 128, 3, 3)\n",
      "(2048, 250)\n",
      "(250, 10)\n",
      "(1, 250)\n",
      "(1, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 21632 into shape (26,26)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m,length,bs):\n\u001b[32m     38\u001b[39m     boi = images[i:(i+bs)].reshape(bs,\u001b[32m1\u001b[39m,\u001b[32m28\u001b[39m,\u001b[32m28\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     rs1 = \u001b[43mReLU_Convolution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mboi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk1\u001b[49m\u001b[43m)\u001b[49m \n\u001b[32m     40\u001b[39m     rs2 = ReLU_Convolution(rs1,k2)\n\u001b[32m     41\u001b[39m     rs3 = ReLU_Convolution(rs2,k3)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mReLU_Convolution\u001b[39m\u001b[34m(batch_of_images, kernel, p, s)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# First operate a reshape keeping spatial ordering, which has channels at the end\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kernel.shape)==\u001b[32m2\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     reshaped_correct_order = \u001b[43mr_c_m\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnih\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mniw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     27\u001b[39m     output_temp = r_c_m.reshape(bs, nih, niw, kc)\n",
      "\u001b[31mValueError\u001b[39m: cannot reshape array of size 21632 into shape (26,26)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "print(numpy_weights)\n",
    "weights_available = True\n",
    "if weights_available:\n",
    "    k1 = numpy_weights['k1']\n",
    "    k2 = numpy_weights['k2']\n",
    "    k3 = numpy_weights['k3']\n",
    "    w1 = numpy_weights['w1']\n",
    "    w2 = numpy_weights['w2']\n",
    "    b1 = numpy_weights['b1']\n",
    "    b2 = numpy_weights['b2']\n",
    "    for i in [k1,k2,k3,w1,w2,b1,b2]:\n",
    "        print(i.shape)\n",
    "else:\n",
    "    #ac is the adaptive channel, the number that corresponds to the amount of channels that the image has\n",
    "    ac, kw, kh, kc = [1,3,3,32]\n",
    "    k1 = np.random.rand(ac*kw*kh*kc).reshape(ac,kw,kh,kc)\n",
    "    kc2 = 64\n",
    "    ac2 = 32\n",
    "    k2 = np.random.rand(ac2*kw*kh*kc2).reshape(ac2,kw,kh,kc2)\n",
    "    h1 = 250\n",
    "    w1 = np.random.rand(1600*250).reshape(1600,250)\n",
    "    b1 = np.random.rand(250).reshape(1,250)\n",
    "    w2 = np.random.rand(250*10).reshape(250,10)\n",
    "    b2 = np.random.rand(10).reshape(1,10)\n",
    "\n",
    "bs=1 # batch size\n",
    "length = 1 #labels.shape[0]\n",
    "lr = 0.01\n",
    "num_epochs = 1\n",
    "correct = 0\n",
    "total = 0\n",
    "loop= tqdm(range(0,num_epochs,bs))\n",
    "for epoch in loop:\n",
    "    avg_loss = []\n",
    "    start_time = time.time()\n",
    "    for i in range(0,length,bs):\n",
    "        boi = images[i:(i+bs)].reshape(bs,1,28,28)\n",
    "        rs1 = ReLU_Convolution(boi,k1) \n",
    "        rs2 = ReLU_Convolution(rs1,k2)\n",
    "        rs3 = ReLU_Convolution(rs2,k3)\n",
    "        i_mlp = rs3.flatten()\n",
    "        fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2)\n",
    "\n",
    "        # Loss\n",
    "        loss = crossEntropy(pred,labels[i:(i+bs)])\n",
    "        avg_loss.append(loss)\n",
    "        if pred == labels[i:(i+bs)]:\n",
    "            correct+= 1\n",
    "        total += 1\n",
    "        # # Backward\n",
    "        # dL_dz2 = pred-labels[i:(i+bs)]\n",
    "        # dL_dw2 = fa.T @ dL_dz2\n",
    "        # dL_db2 = np.sum(dL_dz2, axis=0)\n",
    "        # dL_dfa = dL_dz2 @ w2.T\n",
    "        # dReLU = (fl > 0).astype(float)\n",
    "        # dL_dfl = dL_dfa * dReLU\n",
    "        # print(i_mlp.shape)\n",
    "        # dL_dw1 = i_mlp.reshape(bs, -1).T @ dL_dfl\n",
    "        # dL_db1 = np.sum(dL_dfl, axis=0)\n",
    "        # dL_i_mlp = dL_dfl @ w1.T\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # w1 -= lr*dL_dw1\n",
    "        # b1 -= lr*dL_db1\n",
    "        # w2 -= lr*dL_dw2\n",
    "        # b2 -= lr*dL_db2\n",
    "    loop.set_postfix(average_loss=sum(avg_loss)/len(avg_loss),state=f\"{round(100*i/length,2)}%\",correctness=100*correct/total)\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c9eda",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f18df",
   "metadata": {},
   "source": [
    "### Inefficient Max Pooling Layer VS Efficient Max Pooling layer for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbd63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop with inefficient MaxPooling took: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop with efficient MaxPooling took: 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "################## PARAMETERS ###########################\n",
    "#\n",
    "#bs=1 # batch size\n",
    "##ac is the adaptive channel, the number that corresponds to the amount of channels that the image has\n",
    "#ac, kw, kh, kc = [1,3,3,32]\n",
    "#k1 = np.random.rand(ac*kw*kh*kc).reshape(ac,kw,kh,kc)\n",
    "#kc2 = 64\n",
    "#ac2 = 32\n",
    "#k2 = np.random.rand(ac2*kw*kh*kc2).reshape(ac2,kw,kh,kc2)\n",
    "#h1 = 250\n",
    "#w1 = np.random.rand(1600*250).reshape(1600,250)\n",
    "#b1 = np.random.rand(250).reshape(1,250)\n",
    "#w2 = np.random.rand(250*10).reshape(250,10)\n",
    "#b2 = np.random.rand(10).reshape(1,10)\n",
    "#\n",
    "################## INFERENCE #############################\n",
    "#length = 1000 # images.shape[0]\n",
    "#start_time = time.time()\n",
    "#for i in tqdm(range(0,length,bs)):\n",
    "#    continue\n",
    "#    rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "#    # For convolution only, these are the times for processing all the images\n",
    "#    # 11.0 seconds with bs = 10000\n",
    "#    # 10.0 seconds with bs = 1000\n",
    "#    # 09.9 seconds with bs = 100\n",
    "#    # 08.0 seconds with bs = 10\n",
    "#    # 06.0 seconds with bs = 1\n",
    "#    # Why ? the window creation scales as O(N*W) where W is the window size and N is the dimensions of the image.\n",
    "#    # Since images are stacked, they end up resulting as a single very big image which may cause problems.\n",
    "#    mp1 = MaxPooling2D(rs1)\n",
    "#    rs2 = ReLU_Convolution(mp1,k2)\n",
    "#    mp2 = MaxPooling2D(rs2)\n",
    "#    i_mlp = mp2.flatten()\n",
    "#    fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2) #softmax doesn't work properly if batch_size > 1\n",
    "#end_time = time.time()\n",
    "#print(f\"Loop with inefficient MaxPooling took: {round(end_time-start_time,2)}\")\n",
    "#start_time = time.time()\n",
    "#for i in tqdm(range(0,length,bs)):\n",
    "#    continue\n",
    "#    rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "#    # For convolution only, these are the times for processing all the images\n",
    "#    # 11.0 seconds with bs = 10000\n",
    "#    # 10.0 seconds with bs = 1000\n",
    "#    # 09.9 seconds with bs = 100\n",
    "#    # 08.0 seconds with bs = 10\n",
    "#    # 06.0 seconds with bs = 1\n",
    "#    # Why ? the window creation scales as O(N*W) where W is the window size and N is the dimensions of the image.\n",
    "#    # Since images are stacked, they end up resulting as a single very big image which may cause problems.\n",
    "#    mp1 = MaxPooling2D_Ef(rs1)\n",
    "#    rs2 = ReLU_Convolution(mp1,k2)\n",
    "#    mp2 = MaxPooling2D_Ef(rs2)\n",
    "#    i_mlp = mp2.flatten()\n",
    "#    fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2)\n",
    "#    #loss = crossEntropy\n",
    "#end_time = time.time()\n",
    "#print(f\"Loop with efficient MaxPooling took: {round(end_time-start_time,2)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IndustrialApplications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
