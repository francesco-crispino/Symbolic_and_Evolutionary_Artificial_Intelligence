{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab8cdc5a",
   "metadata": {},
   "source": [
    "# CNN Inference with NumPy\n",
    "In the classic CNN behaviour, we are given an image, the kernel passes over each subset of the image and for each subset it computes the sum of element-wise products. If done with vanilla Python, this procedure results in a slow execution. In PyTorch the problem is solved thanks to the framework given by the module itself. The idea of using numpy consists in transforming the given image in a matrix where each row is composed by one of the subset of the image interested in the convolution with the kernel, then vectorize the kernel and then perform the convolution step by simply operating a dot product between the subset and the kernel. This operation is fast in numpy, which is the Python module responsible for numeric computations. This approach is good but it introduces redundancy in data. A tradeoff between memory and cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842de893",
   "metadata": {},
   "source": [
    "# provare jax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d8cf62",
   "metadata": {},
   "source": [
    "`PLACEHOLDER`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b36d8b",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bce4150",
   "metadata": {},
   "source": [
    "### Kernel Multiplication\n",
    "Convolving an image of dimensions 800 x 600 x 3 where 3 is the number of channels (one for red, one for green and one for blue) with a kernel of size 2x2x3 outputs an image of dimensions 799x599x1. Kernel's number of channels must match the number of channels of the input image. Therefore if i want, for example, to obtain a color image as the result of a convolution, i would need to convolve the input image with three kernels of three channels. Another way to see this is that the number of kernels i use in the convolution will become the number of channels for the output image \n",
    "\n",
    "`X = X[::3,:]` means \"Please select the first three rows of matrix X and return them\"\n",
    "\n",
    "### Channels Problem: How to consider multiple channels:\n",
    "taking the previous matrix as an example, and adding a channel where every number is the corresponding of the first channel but *100 we obtain:\n",
    "01,02,05,06,101,102,105,106\n",
    "Which means just append the next channel's corresponding flattened window to the previous one\n",
    "\n",
    "### Batch Problem: How to consider multiple images:\n",
    "just add the obtained windows at the end of the ones of the previous image, so instead of having a 5 rows 9 columns matrix of windows the result will be a matrix of 10 rows and 9 columns.\n",
    "\n",
    "### Final input management\n",
    "The more images can be stacked in the input, the faster the training will be, therefore the stack dimension must be taken into account. If the desire is to manage stacks of 8, 800x600 resolution color images (numbers were chosen so that they are better recognizable) with a 5x4 kernel, the function to create windows will have this shape:\n",
    "\n",
    "`X = np.random.rand(8*3*800*600).reshape(8,3,800,600)`\n",
    "\n",
    "`y = np.lib.stride_tricks.sliding_window_view(X,(1,3,5,4)).reshape(-1,(3*5*4))`\n",
    "\n",
    "Which translates in:\n",
    "\n",
    "`y = np.lib.stride_tricks.sliding_window_view(X,(1,CHANNEL_SIZE,KERNEL_WIDTH,KERNEL_HEIGHT))`\n",
    "\n",
    "`y = y.reshape(-1,(CHANNEL_SIZE*KERNEL_WIDTH*KERNEL_HEIGHT))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f42f52d",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1739ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trials = True\n",
    "def tprint(value):\n",
    "    print(value) if trials else print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76440db3",
   "metadata": {},
   "source": [
    "### Inefficient Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f245760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPooling2DIneff(batch_of_images,win_size = 2, stride=2):\n",
    "    # very inefficient... but it works...\n",
    "    # it gives the same result as PyTorch's nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "    #print(batch_of_images.shape)\n",
    "    niw = round(iw/2) if iw % 2 == 0 else round(iw/2)-1\n",
    "    nih = round(ih/2) if ih % 2 == 0 else round(ih/2)-1\n",
    "    batch = []\n",
    "    for bb in range(bs):\n",
    "        channel=[]\n",
    "        for cc in range(nc):\n",
    "            y=[]\n",
    "            for i in range(0,ih,stride):\n",
    "                for j in range(0,iw,stride):\n",
    "                    if (j+win_size)>iw:\n",
    "                        continue\n",
    "                    if (i+win_size)>ih:\n",
    "                        continue\n",
    "                    y.append(batch_of_images[bb,cc,i:(i+win_size),j:(j+win_size)].max())\n",
    "            y=np.array(y).reshape(niw,nih)\n",
    "            channel.append(y)\n",
    "        batch.append(channel)\n",
    "    return np.array(batch)\n",
    "## this is an example\n",
    "#X = np.arange(1,(6*6*2*2)+1).reshape(2,2,6,6)\n",
    "#print(X)\n",
    "#r=MaxPooling2D(X)\n",
    "#print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee45ce",
   "metadata": {},
   "source": [
    "### Sliding Window View\n",
    "To implement the im2col convolution approach, the first thing to do is creating the matrix of windows from the given image. This can be done with the helpful function `np.lib.stride_tricks.sliding_window_view(image,kernel_shape)` which exactly returns what this approach needs. In the next panel the functioning of this function will be done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7d5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2  3]\n",
      "   [ 4  5  6]\n",
      "   [ 7  8  9]]\n",
      "\n",
      "  [[10 11 12]\n",
      "   [13 14 15]\n",
      "   [16 17 18]]]\n",
      "\n",
      "\n",
      " [[[19 20 21]\n",
      "   [22 23 24]\n",
      "   [25 26 27]]\n",
      "\n",
      "  [[28 29 30]\n",
      "   [31 32 33]\n",
      "   [34 35 36]]]]\n",
      "desired result\n",
      "[1,2,4,5]\n",
      "[2,3,5,6]\n",
      "...\n",
      "correct one:\n",
      "wrong: after the first window there is the first window of the channel\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,(2*2*3*3)+1).reshape(2,2,3,3)\n",
    "tprint(X)\n",
    "tprint(\"desired result\")\n",
    "tprint(\"[1,2,4,5]\")\n",
    "tprint(\"[2,3,5,6]\")\n",
    "tprint(\"...\")\n",
    "tprint(\"correct one:\")\n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,1,2,2))\n",
    "tprint(\"wrong: after the first window there is the first window of the channel\")\n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,1,2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6965932c",
   "metadata": {},
   "source": [
    "### Back from Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13611bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 2. 0. 0.]\n",
      " [0. 0. 4. 0.]\n",
      " [0. 0. 0. 3.]]\n"
     ]
    }
   ],
   "source": [
    "X= np.zeros(4*4).reshape(4,4)\n",
    "values = np.array([1,2,3,4]).reshape(2,2)\n",
    "indices=np.array([0,1,3,2]).reshape(2,2)\n",
    "print(X)\n",
    "np.add.at(X,(indices,indices),values)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b832470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "row,col\n",
      "[1 0 1 0] [1 0 0 1]\n",
      "r_out_idx\n",
      "[[0 0]\n",
      " [1 1]]\n",
      "c_out_idx\n",
      "[[0 1]\n",
      " [0 1]]\n",
      "vert_start\n",
      "[[0 0]\n",
      " [2 2]]\n",
      "horiz_start\n",
      "[[0 2]\n",
      " [0 2]]\n",
      "idx_row_in_window_reshaped\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "idx_col_in_window_reshaped\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "abs_row_coords\n",
      "[[1 0]\n",
      " [3 2]]\n",
      "abs_col_coords\n",
      "[[1 2]\n",
      " [0 3]]\n",
      "back_X\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "back_X\n",
      "[[0. 0. 3. 0.]\n",
      " [0. 7. 0. 0.]\n",
      " [0. 0. 0. 5.]\n",
      " [4. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.arange(1,17).reshape(4,4)\n",
    "print(X)\n",
    "stride = winSize = 2\n",
    "small_X = np.array([6,5,6,7]).reshape(2,2)\n",
    "small_dX = np.array([7,3,4,5]).reshape(2,2)\n",
    "H_out,W_out = small_dX.shape\n",
    "ind = np.array([3,0,2,1])\n",
    "back_X = np.zeros(X.shape)\n",
    "row = ind // winSize # if [3,3,3,3] // 2 returns [1,1,1,1]\n",
    "col = ind % winSize # if [3,3,3,3] // 2 returns [1,1,1,1]\n",
    "print(\"row,col\")\n",
    "print(row,col)\n",
    "# it means, the first element must be at row one and col one starting from zero.\n",
    "r_out_idx, c_out_idx = np.indices((H_out, W_out))\n",
    "print(\"r_out_idx\")\n",
    "print(r_out_idx)\n",
    "print(\"c_out_idx\")\n",
    "print(c_out_idx)\n",
    "\n",
    "vert_start = r_out_idx * stride # Forma (bs, nc, H_out, W_out)\n",
    "horiz_start = c_out_idx * stride # Forma (bs, nc, H_out, W_out)\n",
    "print(\"vert_start\")\n",
    "print(vert_start)\n",
    "print(\"horiz_start\")\n",
    "print(horiz_start)\n",
    "#    c. Calcola le coordinate assolute finali in dA_prev\n",
    "#       idx_row_in_window e idx_col_in_window devono essere \"broadcastabili\" o\n",
    "#       avere la stessa forma di vert_start e horiz_start se non sono già piatte.\n",
    "#       Poiché indices_flat era (bs*nc*H_out*W_out,), rimodelliamoli:\n",
    "idx_row_in_window_reshaped = row.reshape(H_out, W_out)\n",
    "idx_col_in_window_reshaped = col.reshape(H_out, W_out)\n",
    "print(\"idx_row_in_window_reshaped\")\n",
    "print(idx_row_in_window_reshaped)\n",
    "print(\"idx_col_in_window_reshaped\")\n",
    "print(idx_col_in_window_reshaped)\n",
    "abs_row_coords = vert_start + idx_row_in_window_reshaped # Forma (bs, nc, H_out, W_out)\n",
    "abs_col_coords = horiz_start + idx_col_in_window_reshaped # Forma (bs, nc, H_out, W_out)\n",
    "print(\"abs_row_coords\")\n",
    "print(abs_row_coords)\n",
    "print(\"abs_col_coords\")\n",
    "print(abs_col_coords)\n",
    "# 4. Usa np.add.at per sommare i gradienti d_out nelle posizioni calcolate di dA_prev.\n",
    "#    np.add.at(array, indici, valori_da_aggiungere)\n",
    "#    Gli 'indici' devono essere una tupla di array di indici per ogni dimensione.\n",
    "#    Tutti gli array in 'indici' e 'valori_da_aggiungere' devono essere broadcastabili\n",
    "#    a una forma comune, o essere appiattiti in modo consistente.\n",
    "\n",
    "#    Creiamo gli indici per np.add.at:\n",
    "#    Tutti questi array (b_idx, ch_idx, abs_row_coords, abs_col_coords, d_out)\n",
    "#    hanno già la stessa forma (bs, nc, H_out, W_out), quindi NumPy\n",
    "#    li gestirà elemento per elemento quando usati come indici e valori.\n",
    "\n",
    "indices_for_add_at = (\n",
    "    abs_row_coords,         # Indici per la dimensione altezza di dA_prev\n",
    "    abs_col_coords          # Indici per la dimensione larghezza di dA_prev\n",
    ")\n",
    "print(\"back_X\")\n",
    "print(back_X)\n",
    "np.add.at(back_X, indices_for_add_at, small_dX)\n",
    "print(\"back_X\")\n",
    "print(back_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93155ee2",
   "metadata": {},
   "source": [
    "### Striding\n",
    "The next panel is devoted to explore the striding, achieved using the preceding, function along with the `[:,:,::2,::2]` construct that, respectively, leaves untouched the number of images in the batch and the number of channels, but selects one row every two and one column every two. rows and columns after the sliding window, uniquely identify one window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedbc941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]\n",
      "   [ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]\n",
      "   [25 26 27 28]\n",
      "   [29 30 31 32]]]]\n",
      "[[ 1  2  5  6]\n",
      " [17 18 21 22]\n",
      " [ 3  4  7  8]\n",
      " [19 20 23 24]\n",
      " [ 9 10 13 14]\n",
      " [25 26 29 30]\n",
      " [11 12 15 16]\n",
      " [27 28 31 32]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(1,16*2+1).reshape(1,2,4,4)\n",
    "tprint(X)\n",
    "# basically [::2,::2] selects every two rows and every two columns, where in this case elements are 3 dimensional matrices of 2 by 2 so the \n",
    "# selection eliminates the desired elements, resulting in a stride 2 convolution \n",
    "y = np.lib.stride_tricks.sliding_window_view(X,(1,2,2,2))[:,:,::2,::2]\n",
    "#y = np.lib.stride_tricks.as_strided(X,shape=(2,2),strides=[1,2,3,4])\n",
    "tprint(y.reshape(-1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6087d69f",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b40418",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e55bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7da90c",
   "metadata": {},
   "source": [
    "### Loading images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8634158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_images(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Leggi intestazione: magic number, numero immagini, righe, colonne\n",
    "        magic, num_images, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        # Leggi tutti i pixel e convertili in array numpy\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        # Ridimensiona l'array in (num_images, rows, cols)\n",
    "        images = images.reshape((num_images, rows, cols))\n",
    "    return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        magic, num_labels = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "images = load_mnist_images('MNIST/train-images-idx3-ubyte')\n",
    "labels = load_mnist_labels('MNIST/train-labels-idx1-ubyte')\n",
    "\n",
    "print(images.shape)  # (60000, 28, 28)\n",
    "print(labels.shape)  # (60000,)\n",
    "one_hot_labels = np.zeros(labels.shape[0]*10).reshape((labels.shape[0]),10)\n",
    "for i in range(len(labels)):\n",
    "    one_hot_labels[i][labels[i]]=1\n",
    "labels = one_hot_labels\n",
    "print(labels.shape) # (60000,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89060d9",
   "metadata": {},
   "source": [
    "CNN Structure\n",
    "The goal is achieving over 90% of accuracy with a simple structure, therefore this would be the set of layers:\n",
    "- Convolutional Layer with 32 2x2 filters and ReLU activation: i: (B x C X 28 x 28), o: (B x 32 x 26 x 26)\n",
    "- Max Pooling layer with 2x2 filter: i: (B x 32 x 26 x 26), o: (B x 32 x 13 x 13)\n",
    "- Convolutional Layer with 32 2x2 filters and ReLU activation: i: (B x 13 x 13 x 32), o: (B x 11 x 11 x 64)\n",
    "- Linear Fully Connected Layer with ReLU activation: i: (B x 7744), o: (B x 250)\n",
    "- Linear Fully Connected Layer with Softmax activation: i: (B x 250), o: (B x 10)\n",
    "- Cross-Entropy Loss: -sum(true_probability_distribution*log(predicted_probability_distribution))\n",
    "\n",
    "where B is the batch_size and C is the number of channels, that for MNIST digits is just one, since they are greyscale images.\n",
    "\n",
    "The idea is to reduce everything to a matrix-matrix multiplication which is super fast in NumPy, an optimized mathematical module for Python, by taking an image and create a matrix containing for each row the flattened window that would enter the convolution, as an example:\n",
    "the first 2 flattened windows of this matrix:\n",
    "01,02,03,04\n",
    "05,06,07,08\n",
    "09,10,11,12\n",
    "13,14,15,16\n",
    "for a kernel 2x2 of stride 1 are:\n",
    "01,02,05,06\n",
    "02,03,06,07\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af530dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [4 2]]\n",
      "[[0 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([-4,0,4,2]).reshape(2,2)\n",
    "reluX = np.maximum(0,X)\n",
    "print(reluX)\n",
    "BReluX=reluX\n",
    "BReluX[BReluX>0]=1\n",
    "print(BReluX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0c4d4f",
   "metadata": {},
   "source": [
    "## CNN - Slow Implementation\n",
    "\n",
    "This implementation utilizes four nested loops to compute the convolutions. Each one represents one dimension: batch, channels, width and height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efb324f",
   "metadata": {},
   "source": [
    "### Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57eecf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]\n",
      "   [ 9 10 11 12]\n",
      "   [13 14 15 16]]\n",
      "\n",
      "  [[17 18 19 20]\n",
      "   [21 22 23 24]\n",
      "   [25 26 27 28]\n",
      "   [29 30 31 32]]]]\n",
      "k\n",
      "[[[[1. 1.]\n",
      "   [1. 1.]]\n",
      "\n",
      "  [[1. 1.]\n",
      "   [1. 1.]]]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 124\u001b[39m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mk\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    123\u001b[39m \u001b[38;5;28mprint\u001b[39m(k)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m X_c = \u001b[43mReLU_ConvolutionS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43ms\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mX_c\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    126\u001b[39m \u001b[38;5;28mprint\u001b[39m(X_c)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mReLU_ConvolutionS\u001b[39m\u001b[34m(boi, k, p, s)\u001b[39m\n\u001b[32m     21\u001b[39m input_val = boi[i_bs, i_nc, input_y, input_x]\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Ottieni il peso corrispondente dal kernel\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Indici kernel: [canale_input, indice_kernel_output, indice_larghezza, indice_altezza]\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# secondo l'unpack kw, kh = k.shape[2], k.shape[3]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m kernel_val = \u001b[43mk\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi_nc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_kc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_kh\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Moltiplica e accumula\u001b[39;00m\n\u001b[32m     27\u001b[39m current_sum += input_val * kernel_val\n",
      "\u001b[31mIndexError\u001b[39m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "def ReLU_ConvolutionS(boi,k,p=0,s=1):\n",
    "    #boi stands for batch of images and has these dimensions: Batch_size, Number of Channels, Width, Height.\n",
    "    #k stands for kernel and has these dimensions: Input images' number of channels, number of kernels, Width, Height\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, iw, ih = boi.shape\n",
    "    niw = round(((iw-kw+(2*p))/s)+1) # new image width\n",
    "    nih = round(((ih-kh+(2*p))/s)+1) # new image height\n",
    "    ni= np.zeros(bs*kc*niw*nih).reshape(bs,kc,niw,nih) # new image\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    current_sum = 0.0\n",
    "                    for i_nc in range(nc):\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    input_val = boi[i_bs, i_nc, input_y, input_x]\n",
    "                                    # Ottieni il peso corrispondente dal kernel\n",
    "                                    # Indici kernel: [canale_input, indice_kernel_output, indice_larghezza, indice_altezza]\n",
    "                                    # secondo l'unpack kw, kh = k.shape[2], k.shape[3]\n",
    "                                    kernel_val = k[i_nc, i_kc, i_kw, i_kh]\n",
    "                                    # Moltiplica e accumula\n",
    "                                    current_sum += input_val * kernel_val\n",
    "                    ni[i_bs, i_kc, i_nih, i_niw] = np.maximum(0, current_sum)\n",
    "    return ni\n",
    "\n",
    "def ReLU_ConvolutionS_backward(d_ni, boi, k, ni_forward, p=0, s=1):\n",
    "    \"\"\"\n",
    "    Calcola la backpropagation per la funzione ReLU_ConvolutionS.\n",
    "\n",
    "    Args:\n",
    "        d_ni (np.ndarray): Gradiente della Loss rispetto all'output della convoluzione (ni).\n",
    "                           Dimensioni: (bs, kc, nih, niw).\n",
    "        boi (np.ndarray):  Input batch originale della forward pass.\n",
    "                           Dimensioni: (bs, nc, ih, iw).\n",
    "        k (np.ndarray):    Kernel originali della forward pass.\n",
    "                           Dimensioni: (ac, kc, kw, kh) dove ac=nc.\n",
    "        ni_forward (np.ndarray): Output originale della forward pass (prima del gradiente).\n",
    "                                 Necessario per il gradiente della ReLU.\n",
    "                                 Dimensioni: (bs, kc, nih, niw).\n",
    "        p (int):           Padding usato nella forward pass.\n",
    "        s (int):           Stride usato nella forward pass.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: Una tupla contenente:\n",
    "            - d_boi (np.ndarray): Gradiente della Loss rispetto all'input batch 'boi'.\n",
    "                                  Dimensioni: (bs, nc, ih, iw).\n",
    "            - d_k (np.ndarray):   Gradiente della Loss rispetto ai kernel 'k'.\n",
    "                                  Dimensioni: (ac, kc, kw, kh).\n",
    "    \"\"\"\n",
    "    ac, kc, kw, kh = k.shape\n",
    "    bs, nc, ih, iw = boi.shape\n",
    "    bs_out, kc_out, nih, niw = d_ni.shape # Le dimensioni di d_ni devono corrispondere a ni_forward\n",
    "\n",
    "    if (bs, kc, nih, niw) != ni_forward.shape:\n",
    "        raise ValueError(\"Le dimensioni di d_ni non corrispondono a quelle di ni_forward.\")\n",
    "    if ac != nc:\n",
    "         raise ValueError(f\"Il numero di canali del kernel ({ac}) deve corrispondere al numero di canali dell'immagine ({nc})\")\n",
    "\n",
    "    # Inizializza i gradienti a zero\n",
    "    d_boi = np.zeros_like(boi)\n",
    "    d_k = np.zeros_like(k)\n",
    "\n",
    "    # --- Backpropagation attraverso ReLU ---\n",
    "    # Il gradiente passa solo dove l'output della ReLU (ni_forward) era > 0.\n",
    "    # dL/d(current_sum) = dL/dni * dni/d(current_sum)\n",
    "    #                   = d_ni * (1 if current_sum > 0 else 0)\n",
    "    #                   = d_ni * (1 if ni_forward > 0 else 0)\n",
    "    d_current_sum = d_ni * (ni_forward > 0) # Element-wise multiplication\n",
    "\n",
    "    # --- Calcolo dei Gradienti d_boi e d_k ---\n",
    "    # Iteriamo attraverso gli elementi del gradiente d_current_sum (o d_ni dopo ReLU)\n",
    "    # e propaghiamo il gradiente indietro a d_boi e d_k.\n",
    "\n",
    "    for i_bs in range(bs):\n",
    "        for i_kc in range(kc):\n",
    "            for i_nih in range(nih):\n",
    "                for i_niw in range(niw):\n",
    "                    # Gradiente locale per questa posizione dell'output\n",
    "                    grad_curr = d_current_sum[i_bs, i_kc, i_nih, i_niw]\n",
    "\n",
    "                    # Se il gradiente è zero, non contribuisce ai gradienti precedenti\n",
    "                    if grad_curr == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Propagazione indietro: iteriamo sulla finestra di input/kernel\n",
    "                    # che ha contribuito a questo output\n",
    "                    for i_nc in range(nc): # nc == ac\n",
    "                        for i_kh in range(kh):\n",
    "                            input_y = (i_nih * s) - p + i_kh\n",
    "                            for i_kw in range(kw):\n",
    "                                input_x = (i_niw * s) - p + i_kw\n",
    "\n",
    "                                # Verifica se l'input corrispondente era valido (dentro i limiti)\n",
    "                                if 0 <= input_y < ih and 0 <= input_x < iw:\n",
    "                                    # --- Calcolo d_k ---\n",
    "                                    # dL/dk = dL/d(current_sum) * d(current_sum)/dk\n",
    "                                    # d(current_sum)/dk[c,kc,kw,kh] = boi[bs,c,y_in,x_in]\n",
    "                                    # L'indice del kernel è (i_nc, i_kc, i_kw, i_kh)\n",
    "                                    # L'indice dell'input è (i_bs, i_nc, input_y, input_x)\n",
    "                                    d_k[i_nc, i_kc, i_kw, i_kh] += grad_curr * boi[i_bs, i_nc, input_y, input_x]\n",
    "\n",
    "                                    # --- Calcolo d_boi ---\n",
    "                                    # dL/dboi = dL/d(current_sum) * d(current_sum)/dboi\n",
    "                                    # d(current_sum)/dboi[bs,c,y_in,x_in] = k[c,kc,kw,kh]\n",
    "                                    # L'indice dell'input è (i_bs, i_nc, input_y, input_x)\n",
    "                                    # L'indice del kernel è (i_nc, i_kc, i_kw, i_kh)\n",
    "                                    d_boi[i_bs, i_nc, input_y, input_x] += grad_curr * k[i_nc, i_kc, i_kw, i_kh]\n",
    "\n",
    "    return d_boi, d_k\n",
    "\n",
    "\n",
    "\n",
    "X=np.arange(1,2*4*4+1).reshape(1,2,4,4)\n",
    "k = np.ones(1*2*2*2).reshape(1,2,2,2)\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"k\")\n",
    "print(k)\n",
    "X_c = ReLU_ConvolutionS(X,k,s=2)\n",
    "print(\"X_c\")\n",
    "print(X_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba912c0",
   "metadata": {},
   "source": [
    "### MLP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d45f3810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,axis=-1,keepdims=True))  # for numerical stability\n",
    "    return e_x / np.sum(e_x,axis=-1,keepdims=True)\n",
    "\n",
    "def ReLU_SoftMax_FullyConnected(input_array,w1,b1,w2,b2):\n",
    "    fl = (input_array @ w1)+b1 # first layer\n",
    "    fa = np.maximum(0,fl) # first activation: ReLU\n",
    "    sl = (fa @ w2)+b2 # second layer\n",
    "    sa = softmax(sl) # second activation: SoftMax\n",
    "    return fl,fa,sl,sa\n",
    "\n",
    "#print(softmax([1,2,3,100000]))\n",
    "#print(softmax_no_NS([1,2,3,1000]))\n",
    "#r = np.array(np.array([1,2,777,2]))\n",
    "#print(softmax(r))\n",
    "#r = np.array((np.array([1,2,777,2]),np.array([1,2,777,2]),np.array([1,2,777,2])))\n",
    "#print(softmax(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d55bd88",
   "metadata": {},
   "source": [
    "### Loss Function: Categorical Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8e51c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(p,t):\n",
    "    # p stands for prediction and t stands for true label\n",
    "    # p = [0,0,1] and t = [1,0,0]\n",
    "    p = p+(1/100000) # for numerical stability\n",
    "    return -np.dot(t,np.log(p).T)\n",
    "\n",
    "#c = [1,1000000000000000,1,1]\n",
    "#c = softmax(c)\n",
    "#print(c)\n",
    "#c = crossEntropy(c,[0,1,0,0])\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5112ce4",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0c940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0b5a30",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9925288a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|          | 0/60000 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 145\u001b[39m\n\u001b[32m    139\u001b[39m d_rs1, d_k2 = ReLU_ConvolutionS_backward(d_rs2, rs1, k2, rs2, p=p, s=s)\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# d_rs1 shape: (bs, 32, 14, 14), d_k2 shape: (32, 64, 3, 3)\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# Backprop attraverso Conv1 (Layer 1)\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# Input grad: d_rs1 (bs, 32, 14, 14)\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;66;03m# Restituisce d_boi (non usato qui) e d_k1 (grad per kernel k1)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m _, d_k1 = \u001b[43mReLU_ConvolutionS_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_rs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m=\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# d_k1 shape: (1, 32, 3, 3)\u001b[39;00m\n\u001b[32m    147\u001b[39m \n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# --- Aggiornamento Pesi ---\u001b[39;00m\n\u001b[32m    149\u001b[39m w1 -= lr * dL_dw1\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mReLU_ConvolutionS_backward\u001b[39m\u001b[34m(d_ni, boi, k, ni_forward, p, s)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[33;03mCalcola la backpropagation per la funzione ReLU_ConvolutionS.\u001b[39;00m\n\u001b[32m     34\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     53\u001b[39m \u001b[33;03m                              Dimensioni: (ac, kc, kw, kh).\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     55\u001b[39m ac, kc, kw, kh = k.shape\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m bs, nc, ih, iw = boi.shape\n\u001b[32m     57\u001b[39m bs_out, kc_out, nih, niw = d_ni.shape \u001b[38;5;66;03m# Le dimensioni di d_ni devono corrispondere a ni_forward\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (bs, kc, nih, niw) != ni_forward.shape:\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# --- Parametri Architettura ---\n",
    "num_classes = 10\n",
    "bs = 1 # Batch size (mantenuto a 1 come nell'esempio)\n",
    "input_channels = 1 # Scala di grigi\n",
    "kh, kw = 3, 3      # Dimensione Kernel (Height, Width)\n",
    "s = 2              # Stride per tutte le convoluzioni\n",
    "p = 1              # Padding per tutte le convoluzioni (per cercare di mantenere le dimensioni dimezzate)\n",
    "\n",
    "# Layer 1\n",
    "kc1 = 32           # Numero kernel/canali output Layer 1\n",
    "# Layer 2\n",
    "kc2 = 64           # Numero kernel/canali output Layer 2\n",
    "# Layer 3\n",
    "kc3 = 128          # Numero kernel/canali output Layer 3\n",
    "\n",
    "# Calcolo dimensioni output convoluzioni (per FC layer)\n",
    "# Input: 28x28\n",
    "h_in, w_in = 28, 28\n",
    "h_out1 = int(((h_in - kh + 2 * p) / s) + 1) # (28-3+2)/2 + 1 = 14\n",
    "w_out1 = int(((w_in - kw + 2 * p) / s) + 1) # (28-3+2)/2 + 1 = 14\n",
    "h_out2 = int(((h_out1 - kh + 2 * p) / s) + 1) # (14-3+2)/2 + 1 = 7\n",
    "w_out2 = int(((w_out1 - kw + 2 * p) / s) + 1) # (14-3+2)/2 + 1 = 7\n",
    "h_out3 = int(((h_out2 - kh + 2 * p) / s) + 1) # (7-3+2)/2 + 1 = 4\n",
    "w_out3 = int(((w_out2 - kw + 2 * p) / s) + 1) # (7-3+2)/2 + 1 = 4\n",
    "\n",
    "# Dimensione input per FC layer\n",
    "fc_input_size = kc3 * h_out3 * w_out3 # 128 * 4 * 4 = 2048\n",
    "fc_hidden_size = 250 # Dimensione layer nascosto FC\n",
    "\n",
    "# --- Inizializzazione Pesi ---\n",
    "# Kernel Convoluzionali (Formato: InputChannels, OutputChannels, KernelHeight, KernelWidth)\n",
    "# -> NOTA: Adatto il formato a (in_channels, out_channels, kh, kw) che è più standard\n",
    "#         Se le tue funzioni USANO (in_channels, kw, kh, out_channels) come nel codice\n",
    "#         originale, DEVI aggiustare l'ordine qui sotto E nelle funzioni!\n",
    "#         Assumiamo ora (in_channels, out_channels, kh, kw)\n",
    "\n",
    "# k1: 1 -> 32 channels, kernel 3x3\n",
    "k1 = np.random.randn(input_channels, kc1, kh, kw) * 0.01\n",
    "# k2: 32 -> 64 channels, kernel 3x3\n",
    "k2 = np.random.randn(kc1, kc2, kh, kw) * 0.01\n",
    "# k3: 64 -> 128 channels, kernel 3x3\n",
    "k3 = np.random.randn(kc2, kc3, kh, kw) * 0.01\n",
    "\n",
    "# Pesi Fully Connected\n",
    "# w1: Da output conv flattenato (2048) a hidden layer (250)\n",
    "w1 = np.random.randn(fc_input_size, fc_hidden_size) * 0.01\n",
    "b1 = np.zeros((1, fc_hidden_size))\n",
    "# w2: Da hidden layer (250) a output classes (10)\n",
    "w2 = np.random.randn(fc_hidden_size, num_classes) * 0.01\n",
    "b2 = np.zeros((1, num_classes))\n",
    "\n",
    "# --- Parametri Training ---\n",
    "length = images.shape[0] # Numero totale di immagini\n",
    "lr = 0.001               # Learning rate (ridotto rispetto all'originale)\n",
    "num_epochs = 3           # Aumentato per vedere qualche cambiamento\n",
    "\n",
    "# --- Ciclo di Training ---\n",
    "print(\"Inizio Training...\")\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    start_time = time.time()\n",
    "    # Usiamo tqdm per la barra di progresso sull'intero dataset per epoca\n",
    "    loop = tqdm(range(0, length, bs), desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for i in loop:\n",
    "        # --- Mini-batch ---\n",
    "        images_batch = images[i:(i+bs)] # Shape (bs, 1, 28, 28)\n",
    "        labels_batch = labels[i:(i+bs)] # Shape (bs, 10) - One-hot\n",
    "        print(images_batch.shape)\n",
    "        # --- Forward Pass ---\n",
    "        # Layer 1: Conv + ReLU\n",
    "        # Input: (bs, 1, 28, 28), k1: (1, 32, 3, 3) -> Output: (bs, 32, 14, 14)\n",
    "        rs1 = ReLU_ConvolutionS(images_batch.reshape(1,1,28,28), k1, p=p, s=s)\n",
    "\n",
    "        # Layer 2: Conv + ReLU\n",
    "        # Input: (bs, 32, 14, 14), k2: (32, 64, 3, 3) -> Output: (bs, 64, 7, 7)\n",
    "        rs2 = ReLU_ConvolutionS(rs1, k2, p=p, s=s)\n",
    "\n",
    "        # Layer 3: Conv + ReLU\n",
    "        # Input: (bs, 64, 7, 7), k3: (64, 128, 3, 3) -> Output: (bs, 128, 4, 4)\n",
    "        rs3 = ReLU_ConvolutionS(rs2, k3, p=p, s=s)\n",
    "\n",
    "        # Flatten l'output dell'ultimo layer convoluzionale\n",
    "        # Input: (bs, 128, 4, 4) -> Output: (bs, 2048)\n",
    "        i_mlp = rs3.reshape(bs, -1)\n",
    "\n",
    "        # Layer 4 & 5: Fully Connected + ReLU -> Fully Connected + Softmax\n",
    "        fl, fa, sl, pred = ReLU_SoftMax_FullyConnected(i_mlp, w1, b1, w2, b2)\n",
    "\n",
    "        # --- Loss ---\n",
    "        loss = crossEntropy(pred, labels_batch)\n",
    "        epoch_loss.append(loss)\n",
    "\n",
    "        # --- Backward Pass ---\n",
    "        # Backprop attraverso Softmax + CrossEntropy (semplificato)\n",
    "        # dL/dsl = pred - labels_batch (gradiente dell'output prima di Softmax)\n",
    "        dL_dsl = pred - labels_batch # Shape (bs, 10)\n",
    "\n",
    "        # Backprop attraverso FC2 (Layer 5)\n",
    "        # dL/dw2 = dL/dsl * dsl/dw2 = fa.T @ dL_dsl\n",
    "        dL_dw2 = fa.T @ dL_dsl # Shape (250, 10)\n",
    "        # dL/db2 = sum(dL/dsl)\n",
    "        dL_db2 = np.sum(dL_dsl, axis=0, keepdims=True) # Shape (1, 10)\n",
    "        # dL/dfa = dL/dsl * dsl/dfa = dL_dsl @ w2.T\n",
    "        dL_dfa = dL_dsl @ w2.T # Shape (bs, 250)\n",
    "\n",
    "        # Backprop attraverso ReLU (Layer 4)\n",
    "        # dL/dfl = dL/dfa * dfa/dfl\n",
    "        dReLU = (fl > 0).astype(float) # Gradiente ReLU\n",
    "        dL_dfl = dL_dfa * dReLU # Shape (bs, 250)\n",
    "\n",
    "        # Backprop attraverso FC1 (Layer 4)\n",
    "        # dL/dw1 = dL/dfl * dfl/dw1 = i_mlp.T @ dL_dfl\n",
    "        dL_dw1 = i_mlp.T @ dL_dfl # Shape (2048, 250)\n",
    "        # dL/db1 = sum(dL/dfl)\n",
    "        dL_db1 = np.sum(dL_dfl, axis=0, keepdims=True) # Shape (1, 250)\n",
    "        # dL/di_mlp = dL/dfl * dfl/di_mlp = dL_dfl @ w1.T\n",
    "        dL_di_mlp = dL_dfl @ w1.T # Shape (bs, 2048)\n",
    "\n",
    "        # Backprop attraverso Flatten (Layer 3 output)\n",
    "        # Reshape del gradiente per matchare l'output del conv layer 3\n",
    "        # Input grad: (bs, 2048) -> Output grad: (bs, 128, 4, 4)\n",
    "        d_rs3 = dL_di_mlp.reshape(rs3.shape)\n",
    "\n",
    "        # Backprop attraverso Conv3 (Layer 3)\n",
    "        # Input grad: d_rs3 (bs, 128, 4, 4)\n",
    "        # Restituisce d_rs2 (grad per l'input rs2) e d_k3 (grad per kernel k3)\n",
    "        d_rs2, d_k3 = ReLU_ConvolutionS_backward(d_rs3, rs2, k3, rs3, p=p, s=s)\n",
    "        # d_rs2 shape: (bs, 64, 7, 7), d_k3 shape: (64, 128, 3, 3)\n",
    "\n",
    "        # Backprop attraverso Conv2 (Layer 2)\n",
    "        # Input grad: d_rs2 (bs, 64, 7, 7)\n",
    "        # Restituisce d_rs1 (grad per l'input rs1) e d_k2 (grad per kernel k2)\n",
    "        d_rs1, d_k2 = ReLU_ConvolutionS_backward(d_rs2, rs1, k2, rs2, p=p, s=s)\n",
    "        # d_rs1 shape: (bs, 32, 14, 14), d_k2 shape: (32, 64, 3, 3)\n",
    "\n",
    "        # Backprop attraverso Conv1 (Layer 1)\n",
    "        # Input grad: d_rs1 (bs, 32, 14, 14)\n",
    "        # Restituisce d_boi (non usato qui) e d_k1 (grad per kernel k1)\n",
    "        _, d_k1 = ReLU_ConvolutionS_backward(d_rs1, images_batch, k1, rs1, p=p, s=s)\n",
    "        # d_k1 shape: (1, 32, 3, 3)\n",
    "\n",
    "        # --- Aggiornamento Pesi ---\n",
    "        w1 -= lr * dL_dw1\n",
    "        b1 -= lr * dL_db1\n",
    "        w2 -= lr * dL_dw2\n",
    "        b2 -= lr * dL_db2\n",
    "        k1 -= lr * d_k1\n",
    "        k2 -= lr * d_k2\n",
    "        k3 -= lr * d_k3\n",
    "\n",
    "        # Aggiorna la barra di progresso con la loss media finora\n",
    "        loop.set_postfix(loss=f\"{np.mean(epoch_loss):.4f}\")\n",
    "\n",
    "    # Fine Epoch\n",
    "    end_time = time.time()\n",
    "    avg_epoch_loss = np.mean(epoch_loss)\n",
    "    print(f\"Epoch {epoch+1} completata in {end_time - start_time:.2f}s - Loss Media: {avg_epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training Completato.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdfa23",
   "metadata": {},
   "source": [
    "## CNN - Fast Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8946b2c",
   "metadata": {},
   "source": [
    "### Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9662d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "k\n",
      "[[1. 1.]\n",
      " [1. 1.]]\n",
      "X_c\n",
      "[[14. 22.]\n",
      " [46. 54.]]\n",
      "This is the backward of the ReLU Convolution\n",
      "dX,X,kernel shapes\n",
      "(1, 4)\n",
      "(9, 4)\n",
      "(4, 1)\n"
     ]
    }
   ],
   "source": [
    "def ReLU_Convolution(batch_of_images,kernel,p=0,s=1):\n",
    "    if len(kernel.shape)==2:\n",
    "        kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        nc = 1\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "    else:\n",
    "        ac, kc, kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        #p = 0 # padding\n",
    "        #s = 1 # stride\n",
    "        # im2col: Window creation\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "    # Convolution\n",
    "    kernel = kernel.reshape((kw*kh*nc),-1)\n",
    "    c_m = window_m @ kernel # convolved image matrix\n",
    "    # ReLU activation\n",
    "    r_c_m = np.maximum(0,c_m) # convolved image matrix after ReLU activation\n",
    "    \n",
    "    niw = round(((iw-kw+(2*p))/s)+1) # new image width\n",
    "    nih = round(((ih-kh+(2*p))/s)+1) # new image height\n",
    "    \n",
    "    # First operate a reshape keeping spatial ordering, which has channels at the end\n",
    "    if len(kernel.shape)==2:\n",
    "        reshaped_correct_order = r_c_m.reshape(nih, niw)\n",
    "    else:\n",
    "        output_temp = r_c_m.reshape(bs, nih, niw, kc)\n",
    "        # Transpose to have input in shapes (batch, canali_output, height, width)\n",
    "        reshaped_correct_order = output_temp.transpose(0, 3, 1, 2)\n",
    "    return reshaped_correct_order\n",
    "\n",
    "\n",
    "def ReLU_Convolution_Backward(batch_of_images,kernel,dX,p=0,s=1):\n",
    "    print(\"This is the backward of the ReLU Convolution\")\n",
    "    if len(kernel.shape)==2:\n",
    "        kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        nc = 1\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "        window_m_dx = np.lib.stride_tricks.sliding_window_view(dX,(kw,kh))[::s,::s].reshape(-1,(kw*kh*nc)) # window matrix of dX\n",
    "    else:\n",
    "        ac, kc, kw, kh = kernel.shape # kernel width, height and number of channels\n",
    "        bs, nc, iw, ih = batch_of_images.shape # batch of images' number of images, number of channels, single image's width, single images's height\n",
    "        #p = 0 # padding\n",
    "        #s = 1 # stride\n",
    "        # im2col: Window creation\n",
    "        window_m = np.lib.stride_tricks.sliding_window_view(batch_of_images,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix\n",
    "        window_m_dx = np.lib.stride_tricks.sliding_window_view(dX,(1,nc,kw,kh))[:,:,::s,::s].reshape(-1,(kw*kh*nc)) # window matrix of dX\n",
    "    # Convolution\n",
    "    kernel = kernel.reshape((kw*kh*nc),-1)\n",
    "    c_m = window_m @ kernel # convolved image matrix\n",
    "    # ReLU activation\n",
    "    r_c_m = np.maximum(0,c_m) # convolved image matrix after ReLU activation\n",
    "    r_c_m[r_c_m>0]=1 # Backward ReLU\n",
    "    print(\"dX,X,kernel shapes\")\n",
    "    print(window_m_dx.shape)\n",
    "    print(window_m.shape)\n",
    "    print(kernel.shape)\n",
    "\n",
    "\n",
    "X=np.arange(1,4*4+1).reshape(4,4)\n",
    "k = np.ones(1*2*2).reshape(2,2)\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"k\")\n",
    "print(k)\n",
    "X_c = ReLU_Convolution(X,k,s=2)\n",
    "print(\"X_c\")\n",
    "print(X_c)\n",
    "ReLU_Convolution_Backward(X,k,X_c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76201de3",
   "metadata": {},
   "source": [
    "### Max Pooling Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxPooling(boi, winSize=2, stride=2):\n",
    "    bs, nc, H_in, W_in = boi.shape\n",
    "\n",
    "    H_out = math.floor((H_in - winSize) / stride) + 1\n",
    "    W_out = math.floor((W_in - winSize) / stride) + 1\n",
    "\n",
    "    output_window_shape = (bs, nc, H_out, W_out, winSize, winSize)\n",
    "    \n",
    "    y_windows = np.lib.stride_tricks.as_strided(boi, shape=output_window_shape)\n",
    "\n",
    "    reshaped_y_for_max = y_windows.reshape(bs * nc * H_out * W_out, winSize * winSize)\n",
    "    \n",
    "    indices = np.argmax(reshaped_y_for_max, axis=1) # Indici piatti (0 a winSize*winSize-1)\n",
    "    max_values = reshaped_y_for_max.max(axis=1)\n",
    "    \n",
    "    pooled_output = max_values.reshape(bs, nc, H_out, W_out)\n",
    "    \n",
    "    cache = (boi.shape, indices, winSize, stride) # indices è 1D\n",
    "    return pooled_output, cache\n",
    "\n",
    "def BackwardMaxPooling(d_out, cache):\n",
    "\n",
    "    A_prev_shape, indices_flat, winSize, stride = cache\n",
    "    bs, nc, H_prev, W_prev = A_prev_shape\n",
    "    _, _, H_out, W_out = d_out.shape\n",
    "\n",
    "    dA_prev = np.zeros(A_prev_shape)\n",
    "\n",
    "    idx_row_in_window = indices_flat // winSize\n",
    "    idx_col_in_window = indices_flat % winSize  \n",
    "\n",
    "\n",
    "    b_idx, ch_idx, r_out_idx, c_out_idx = np.indices((bs, nc, H_out, W_out))\n",
    "\n",
    "    vert_start = r_out_idx * stride \n",
    "    horiz_start = c_out_idx * stride \n",
    "\n",
    "    idx_row_in_window_reshaped = idx_row_in_window.reshape(bs, nc, H_out, W_out)\n",
    "    idx_col_in_window_reshaped = idx_col_in_window.reshape(bs, nc, H_out, W_out)\n",
    "    \n",
    "    abs_row_coords = vert_start + idx_row_in_window_reshaped \n",
    "    abs_col_coords = horiz_start + idx_col_in_window_reshaped \n",
    "    \n",
    "    indices_for_add_at = (\n",
    "        b_idx,                  \n",
    "        ch_idx,                 \n",
    "        abs_row_coords,         \n",
    "        abs_col_coords        \n",
    "    )\n",
    "    \n",
    "    np.add.at(dA_prev, indices_for_add_at, d_out)\n",
    "    \n",
    "    return dA_prev\n",
    "\n",
    "#X = np.arange(1,33).reshape(2,1,4,4)\n",
    "#X[0,0,0,0]=100\n",
    "#\n",
    "#pooled,cache = MaxPooling2D(X)\n",
    "#print(cache)\n",
    "#dX = np.array([1,5,2,9,4,3,2,8]).reshape(2,1,2,2)\n",
    "#new_X = backward_maxpool_vectorized(dX,cache)\n",
    "#print(new_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b58b263",
   "metadata": {},
   "source": [
    "### MLP Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9773f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x,axis=-1,keepdims=True))  # for numerical stability\n",
    "    return e_x / np.sum(e_x,axis=-1,keepdims=True)\n",
    "\n",
    "def ReLU_SoftMax_FullyConnected(input_array,w1,b1,w2,b2):\n",
    "    fl = (input_array @ w1)+b1 # first layer\n",
    "    fa = np.maximum(0,fl) # first activation: ReLU\n",
    "    sl = (fa @ w2)+b2 # second layer\n",
    "    sa = softmax(sl) # second activation: SoftMax\n",
    "    return fl,fa,sl,sa\n",
    "\n",
    "#print(softmax([1,2,3,100000]))\n",
    "#print(softmax_no_NS([1,2,3,1000]))\n",
    "#r = np.array(np.array([1,2,777,2]))\n",
    "#print(softmax(r))\n",
    "#r = np.array((np.array([1,2,777,2]),np.array([1,2,777,2]),np.array([1,2,777,2])))\n",
    "#print(softmax(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92146a63",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "For this classification problem, the best loss function is the cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819749e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossEntropy(p,t):\n",
    "    # p stands for prediction and t stands for true label\n",
    "    # p = [0,0,1] and t = [1,0,0]\n",
    "    p = p+(1/100000) # for numerical stability\n",
    "    return -np.dot(t,np.log(p).T)\n",
    "\n",
    "#c = [1,1000000000000000,1,1]\n",
    "#c = softmax(c)\n",
    "#print(c)\n",
    "#c = crossEntropy(c,[0,1,0,0])\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe07056",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9223383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.24it/s, average_loss=[[2.27330587]], state=0.0%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "bs=1 # batch size\n",
    "#ac is the adaptive channel, the number that corresponds to the amount of channels that the image has\n",
    "ac, kw, kh, kc = [1,3,3,32]\n",
    "k1 = np.random.rand(ac*kw*kh*kc).reshape(ac,kw,kh,kc)\n",
    "kc2 = 64\n",
    "ac2 = 32\n",
    "k2 = np.random.rand(ac2*kw*kh*kc2).reshape(ac2,kw,kh,kc2)\n",
    "h1 = 250\n",
    "w1 = np.random.rand(1600*250).reshape(1600,250)\n",
    "b1 = np.random.rand(250).reshape(1,250)\n",
    "w2 = np.random.rand(250*10).reshape(250,10)\n",
    "b2 = np.random.rand(10).reshape(1,10)\n",
    "length = 1 #labels.shape[0]\n",
    "lr = 0.01\n",
    "num_epochs = 1\n",
    "loop= tqdm(range(0,num_epochs,bs))\n",
    "for epoch in loop:\n",
    "    avg_loss = []\n",
    "    start_time = time.time()\n",
    "    for i in range(0,length,bs):\n",
    "        rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "        loop.set_postfix(average_loss=sum(avg_loss)/(len(avg_loss)+1),state=f\"{round(100*i/length,2)}%\")\n",
    "        im_sh1,mpInd1,mp1 = MaxPooling(rs1)\n",
    "        rs2 = ReLU_Convolution(mp1,k2)\n",
    "        im_sh2,mpInd2,mp2 = MaxPooling(rs2)\n",
    "        i_mlp = mp2.flatten()\n",
    "        fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2)\n",
    "\n",
    "        # Loss\n",
    "        loss = crossEntropy(pred,labels[i:(i+bs)])\n",
    "        avg_loss.append(loss)\n",
    "\n",
    "        # Backward\n",
    "        dL_dz2 = pred-labels[i:(i+bs)]\n",
    "        dL_dw2 = fa.T @ dL_dz2\n",
    "        dL_db2 = np.sum(dL_dz2, axis=0)\n",
    "        dL_dfa = dL_dz2 @ w2.T\n",
    "        dReLU = (fl > 0).astype(float)\n",
    "        dL_dfl = dL_dfa * dReLU\n",
    "        print(i_mlp.shape)\n",
    "        dL_dw1 = i_mlp.reshape(bs, -1).T @ dL_dfl\n",
    "        dL_db1 = np.sum(dL_dfl, axis=0)\n",
    "        dL_i_mlp = dL_dfl @ w1.T\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        w1 -= lr*dL_dw1\n",
    "        b1 -= lr*dL_db1\n",
    "        w2 -= lr*dL_dw2\n",
    "        b2 -= lr*dL_db2\n",
    "    loop.set_postfix(average_loss=sum(avg_loss)/len(avg_loss),state=f\"{round(100*i/length,2)}%\")\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9c9eda",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9f18df",
   "metadata": {},
   "source": [
    "### Inefficient Max Pooling Layer VS Efficient Max Pooling layer for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbd63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop with inefficient MaxPooling took: 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop with efficient MaxPooling took: 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#import time\n",
    "################## PARAMETERS ###########################\n",
    "#\n",
    "#bs=1 # batch size\n",
    "##ac is the adaptive channel, the number that corresponds to the amount of channels that the image has\n",
    "#ac, kw, kh, kc = [1,3,3,32]\n",
    "#k1 = np.random.rand(ac*kw*kh*kc).reshape(ac,kw,kh,kc)\n",
    "#kc2 = 64\n",
    "#ac2 = 32\n",
    "#k2 = np.random.rand(ac2*kw*kh*kc2).reshape(ac2,kw,kh,kc2)\n",
    "#h1 = 250\n",
    "#w1 = np.random.rand(1600*250).reshape(1600,250)\n",
    "#b1 = np.random.rand(250).reshape(1,250)\n",
    "#w2 = np.random.rand(250*10).reshape(250,10)\n",
    "#b2 = np.random.rand(10).reshape(1,10)\n",
    "#\n",
    "################## INFERENCE #############################\n",
    "#length = 1000 # images.shape[0]\n",
    "#start_time = time.time()\n",
    "#for i in tqdm(range(0,length,bs)):\n",
    "#    continue\n",
    "#    rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "#    # For convolution only, these are the times for processing all the images\n",
    "#    # 11.0 seconds with bs = 10000\n",
    "#    # 10.0 seconds with bs = 1000\n",
    "#    # 09.9 seconds with bs = 100\n",
    "#    # 08.0 seconds with bs = 10\n",
    "#    # 06.0 seconds with bs = 1\n",
    "#    # Why ? the window creation scales as O(N*W) where W is the window size and N is the dimensions of the image.\n",
    "#    # Since images are stacked, they end up resulting as a single very big image which may cause problems.\n",
    "#    mp1 = MaxPooling2D(rs1)\n",
    "#    rs2 = ReLU_Convolution(mp1,k2)\n",
    "#    mp2 = MaxPooling2D(rs2)\n",
    "#    i_mlp = mp2.flatten()\n",
    "#    fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2) #softmax doesn't work properly if batch_size > 1\n",
    "#end_time = time.time()\n",
    "#print(f\"Loop with inefficient MaxPooling took: {round(end_time-start_time,2)}\")\n",
    "#start_time = time.time()\n",
    "#for i in tqdm(range(0,length,bs)):\n",
    "#    continue\n",
    "#    rs1 = ReLU_Convolution(images[i:(i+bs)].reshape(bs,1,28,28),k1) \n",
    "#    # For convolution only, these are the times for processing all the images\n",
    "#    # 11.0 seconds with bs = 10000\n",
    "#    # 10.0 seconds with bs = 1000\n",
    "#    # 09.9 seconds with bs = 100\n",
    "#    # 08.0 seconds with bs = 10\n",
    "#    # 06.0 seconds with bs = 1\n",
    "#    # Why ? the window creation scales as O(N*W) where W is the window size and N is the dimensions of the image.\n",
    "#    # Since images are stacked, they end up resulting as a single very big image which may cause problems.\n",
    "#    mp1 = MaxPooling2D_Ef(rs1)\n",
    "#    rs2 = ReLU_Convolution(mp1,k2)\n",
    "#    mp2 = MaxPooling2D_Ef(rs2)\n",
    "#    i_mlp = mp2.flatten()\n",
    "#    fl,fa,sl,pred = ReLU_SoftMax_FullyConnected(i_mlp,w1,b1,w2,b2)\n",
    "#    #loss = crossEntropy\n",
    "#end_time = time.time()\n",
    "#print(f\"Loop with efficient MaxPooling took: {round(end_time-start_time,2)} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IndustrialApplications",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
